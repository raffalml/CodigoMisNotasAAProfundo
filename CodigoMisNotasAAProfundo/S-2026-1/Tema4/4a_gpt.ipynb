{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/2026-1/notebooks/4a_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zqNl1jobIA4"
      },
      "source": [
        "# Aplicaciones de Transformers (GPT)\n",
        "\n",
        "---\n",
        "Curso: Aprendizaje Profundo.\n",
        "\n",
        "Profesor: Gibran Fuentes Pineda.\n",
        "\n",
        "Ayudantes: Fernando Nava y Rodrigo del Moral\n",
        "\n",
        "---\n",
        "\n",
        "En esta libreta se explora una aplicación de los bloques Transformers. El código utiliza el bloque Transformer visto en clase y el modelo está basado en una implementación conocida como [nanoGPT](https://github.com/karpathy/nanoGPT/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0VTSiNcbIA6"
      },
      "source": [
        "## 1. Importar bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjjvMifYZf7x"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from collections import Counter\n",
        "from torchsummary import summary\n",
        "\n",
        "th.manual_seed(22)\n",
        "device = 'cuda' if th.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmHEeS88bIA7"
      },
      "source": [
        "## 2. Conjunto de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cUTEbwHbIA7",
        "outputId": "8a2ca1da-dd70-42c8-c02e-ea1ae93f9f96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-21 17:08:59--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-10-21 17:09:00 (100 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# descargar y abrir archivo (obras completas de Shakespeare en inglés)\n",
        "if not os.path.exists(\"input.txt\"):\n",
        "  ! wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()\n",
        "\n",
        "# generar el vocabulario del tokenizador (caracteres)\n",
        "voc = Counter([c for c in text])\n",
        "\n",
        "# crear diccionarios para mapear IDs y tokens\n",
        "i2p = {i:p for i,(p,f) in enumerate(voc.most_common())}\n",
        "p2i = {p:i for i,(p,f) in enumerate(voc.most_common())}\n",
        "\n",
        "# tamaño del vocabulario\n",
        "vocab_size = len(i2p)\n",
        "\n",
        "# crear funciones para convertir de IDs a tokens y viceversa\n",
        "encode = lambda s: [p2i[c] for c in s]\n",
        "decode = lambda l: ''.join([i2p[i] for i in l])\n",
        "\n",
        "# codificar el conjunto de datos entero y partirlo en train y valid\n",
        "data = th.tensor(encode(text), dtype=th.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EjoWuS1EaYP",
        "outputId": "f5103225-957e-4c8a-cd4c-7e0e5ad4c76b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "len(voc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7V7rVPAXbIA7"
      },
      "source": [
        "## 3. Cargador de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CWYpgPx2bIA8"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "context_size = 32\n",
        "\n",
        "# para generar los datos del modelo de lenguaje causal (predecir siguiente token)\n",
        "# las entradas son porciones de texto codificadas de tamaño context_size y\n",
        "# las salidas son las mismas porciones de texto recorridas un paso\n",
        "def get_batch(split):\n",
        "  data = train_data if split == 'train' else val_data\n",
        "  ix = th.randint(len(data) - context_size, (batch_size,))\n",
        "  x = th.stack([data[i:i+context_size] for i in ix])\n",
        "  y = th.stack([data[i+1:i+context_size+1] for i in ix])\n",
        "  x, y = x.to(device), y.to(device)\n",
        "  return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ8ICDRFFG-W",
        "outputId": "a2056b07-ff8c-4652-eeac-fec4a411d3f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[14, 18,  3,  7,  2, 46, 10, 43, 15,  0,  4,  8, 12,  0, 22, 15, 25, 10,\n",
              "          21,  0,  5,  3, 23,  1,  0,  9,  2,  0,  9,  6,  0,  6],\n",
              "         [ 3, 13,  8,  2,  4,  9,  8, 16, 10, 49,  7,  3, 14,  0, 17,  5,  1,  8,\n",
              "           0,  2,  5,  9,  6,  0,  6,  2,  7,  1,  4, 14,  0,  2],\n",
              "         [ 5,  9,  6, 10, 27,  1,  7, 15,  0, 12,  4, 15,  0,  7,  1, 19,  1,  9,\n",
              "          27,  1,  6,  0, 11,  1,  2,  2,  1,  7,  6,  0,  3, 18],\n",
              "         [ 6,  0, 17,  1, 11, 11, 16,  0,  4,  8, 12,  0,  8,  3,  2,  5,  9,  8,\n",
              "          20,  0, 19,  4,  8,  0, 22,  1,  0,  9, 11, 11, 24, 10],\n",
              "         [ 3, 14, 23, 11,  3,  2,  2,  1, 12,  0,  4,  8, 12,  0, 19,  3,  8,  2,\n",
              "           7,  9, 27,  1, 12,  0,  9,  8,  0,  2,  5,  9,  6,  0],\n",
              "         [ 0,  2,  5,  1,  1,  0,  3,  8,  0,  2,  5, 15,  0, 17,  4, 15,  0,  2,\n",
              "           3,  0, 42,  4,  8,  2, 13,  4, 24, 10, 29,  5,  1,  7],\n",
              "         [ 1, 12, 10,  2,  5,  1,  1,  0,  6,  2,  7,  4,  9, 20,  5,  2, 16, 10,\n",
              "          26,  8, 12,  0, 14,  4, 28,  1,  0, 14, 15,  0, 14,  9],\n",
              "         [27,  1,  8,  0,  8,  3, 17,  0,  2,  5,  1,  0, 18,  7,  3, 57,  1,  8,\n",
              "           0, 22,  3,  6,  3, 14,  0,  3, 18,  0,  2,  5,  1,  0],\n",
              "         [ 0, 22,  7,  1,  4,  2,  5,  0,  3, 18,  0, 20,  1,  8,  2, 11,  1,  0,\n",
              "           6, 11,  1,  1, 23, 38, 10, 39,  5,  9, 19,  5,  0,  6],\n",
              "         [ 1,  0, 14, 13,  6,  2,  0, 22,  1,  0,  2,  3, 11, 12,  0,  3,  8, 30,\n",
              "           2, 16,  0,  4,  8, 12,  0,  5,  1,  0,  6,  5,  4, 11],\n",
              "         [16,  0,  3,  7,  0, 19,  5,  9, 11, 12, 25, 10, 10, 51, 32, 42, 51, 31,\n",
              "          50, 24, 10, 35,  9,  7, 16,  0,  6,  5,  1,  0, 17,  4],\n",
              "         [ 0, 13, 23,  3,  8,  0,  4,  0,  6, 13, 22,  2, 11,  1,  0, 20,  7,  3,\n",
              "          13,  8, 12, 16, 10, 21,  0,  5,  4, 27,  1,  0,  2, 13],\n",
              "         [ 4, 28,  1,  0, 22,  3, 11, 12,  0, 17,  9,  2,  5,  4, 11, 16,  0,  4,\n",
              "           8, 12,  0,  4,  6,  0, 15,  3, 13, 10,  6,  5,  4, 11],\n",
              "         [ 4, 15,  0, 15,  3, 13, 16,  0, 11,  1,  2, 30,  6,  0,  5,  1,  4,  7,\n",
              "          25, 10, 10, 51,  7,  3, 27,  3,  6,  2, 24, 10, 10, 47],\n",
              "         [ 5,  1,  7, 38, 10, 21, 30, 11, 11,  0,  5,  1,  8, 19,  1,  0,  2,  3,\n",
              "           0, 36,  3,  8, 12,  3,  8,  0,  3,  8,  0,  4,  0,  6],\n",
              "         [12, 16,  0, 19,  7, 15,  0, 30, 17,  3,  1, 46, 30,  0,  2,  5,  1,  0,\n",
              "          55, 13,  1,  1,  8, 16,  0,  2,  5,  1,  0, 55, 13,  1]],\n",
              "        device='cuda:0'),\n",
              " tensor([[18,  3,  7,  2, 46, 10, 43, 15,  0,  4,  8, 12,  0, 22, 15, 25, 10, 21,\n",
              "           0,  5,  3, 23,  1,  0,  9,  2,  0,  9,  6,  0,  6,  3],\n",
              "         [13,  8,  2,  4,  9,  8, 16, 10, 49,  7,  3, 14,  0, 17,  5,  1,  8,  0,\n",
              "           2,  5,  9,  6,  0,  6,  2,  7,  1,  4, 14,  0,  2,  5],\n",
              "         [ 9,  6, 10, 27,  1,  7, 15,  0, 12,  4, 15,  0,  7,  1, 19,  1,  9, 27,\n",
              "           1,  6,  0, 11,  1,  2,  2,  1,  7,  6,  0,  3, 18,  0],\n",
              "         [ 0, 17,  1, 11, 11, 16,  0,  4,  8, 12,  0,  8,  3,  2,  5,  9,  8, 20,\n",
              "           0, 19,  4,  8,  0, 22,  1,  0,  9, 11, 11, 24, 10, 41],\n",
              "         [14, 23, 11,  3,  2,  2,  1, 12,  0,  4,  8, 12,  0, 19,  3,  8,  2,  7,\n",
              "           9, 27,  1, 12,  0,  9,  8,  0,  2,  5,  9,  6,  0, 11],\n",
              "         [ 2,  5,  1,  1,  0,  3,  8,  0,  2,  5, 15,  0, 17,  4, 15,  0,  2,  3,\n",
              "           0, 42,  4,  8,  2, 13,  4, 24, 10, 29,  5,  1,  7,  1],\n",
              "         [12, 10,  2,  5,  1,  1,  0,  6,  2,  7,  4,  9, 20,  5,  2, 16, 10, 26,\n",
              "           8, 12,  0, 14,  4, 28,  1,  0, 14, 15,  0, 14,  9,  6],\n",
              "         [ 1,  8,  0,  8,  3, 17,  0,  2,  5,  1,  0, 18,  7,  3, 57,  1,  8,  0,\n",
              "          22,  3,  6,  3, 14,  0,  3, 18,  0,  2,  5,  1,  0,  8],\n",
              "         [22,  7,  1,  4,  2,  5,  0,  3, 18,  0, 20,  1,  8,  2, 11,  1,  0,  6,\n",
              "          11,  1,  1, 23, 38, 10, 39,  5,  9, 19,  5,  0,  6,  3],\n",
              "         [ 0, 14, 13,  6,  2,  0, 22,  1,  0,  2,  3, 11, 12,  0,  3,  8, 30,  2,\n",
              "          16,  0,  4,  8, 12,  0,  5,  1,  0,  6,  5,  4, 11, 11],\n",
              "         [ 0,  3,  7,  0, 19,  5,  9, 11, 12, 25, 10, 10, 51, 32, 42, 51, 31, 50,\n",
              "          24, 10, 35,  9,  7, 16,  0,  6,  5,  1,  0, 17,  4,  6],\n",
              "         [13, 23,  3,  8,  0,  4,  0,  6, 13, 22,  2, 11,  1,  0, 20,  7,  3, 13,\n",
              "           8, 12, 16, 10, 21,  0,  5,  4, 27,  1,  0,  2, 13, 14],\n",
              "         [28,  1,  0, 22,  3, 11, 12,  0, 17,  9,  2,  5,  4, 11, 16,  0,  4,  8,\n",
              "          12,  0,  4,  6,  0, 15,  3, 13, 10,  6,  5,  4, 11, 11],\n",
              "         [15,  0, 15,  3, 13, 16,  0, 11,  1,  2, 30,  6,  0,  5,  1,  4,  7, 25,\n",
              "          10, 10, 51,  7,  3, 27,  3,  6,  2, 24, 10, 10, 47, 40],\n",
              "         [ 1,  7, 38, 10, 21, 30, 11, 11,  0,  5,  1,  8, 19,  1,  0,  2,  3,  0,\n",
              "          36,  3,  8, 12,  3,  8,  0,  3,  8,  0,  4,  0,  6,  1],\n",
              "         [16,  0, 19,  7, 15,  0, 30, 17,  3,  1, 46, 30,  0,  2,  5,  1,  0, 55,\n",
              "          13,  1,  1,  8, 16,  0,  2,  5,  1,  0, 55, 13,  1,  1]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "get_batch(\"train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXD-kJsYbIA8"
      },
      "source": [
        "## 4. Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HLT2dSMbIA8"
      },
      "outputs": [],
      "source": [
        "max_iters = 50000      # pasos de entrenamiento\n",
        "eval_interval = 500    # cada cuántos pasos calcular (train/valid) durante el entrenamiento\n",
        "learning_rate = 1e-3\n",
        "eval_iters = 200       # tamaño de la muestra para promediar en el cálculo de la pérdida\n",
        "n_embd = 64            # tamaño de los embeddings internos\n",
        "n_head = 4             # numero de cabezas de auto-atención\n",
        "n_layer = 4            # numero de bloques Transformers\n",
        "dropout = 0.2          # aplicado después de cada autoatención, FF, y enmascarado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jBpuK1mbIA9"
      },
      "source": [
        "## 5. Módulos Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQoV4Pa6bIA-"
      },
      "outputs": [],
      "source": [
        "class ProductoPuntoEscalado(nn.Module):\n",
        "  def __init__(self,\n",
        "               p_dropout = 0.0,\n",
        "               masc = False):\n",
        "    super(ProductoPuntoEscalado, self).__init__()\n",
        "    self.masc = masc\n",
        "    self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "  def forward(self, Q, K, V):\n",
        "    # Obtenemos dimensiones\n",
        "    m, n_cabezas, l, d_k = K.shape\n",
        "    d_v = V.shape[-1]\n",
        "\n",
        "    # Cambiamos la forma: [m, n_cabezas, l, d_k] -> [m * n_cabezas, l, d_k]\n",
        "    Q = Q.reshape(m * n_cabezas, l, d_k)\n",
        "    K = K.reshape(m * n_cabezas, l, d_k)\n",
        "    V = V.reshape(m * n_cabezas, l, d_v)\n",
        "\n",
        "    # Q y K tienen forma [m * n_cabezas, l, d_k],\n",
        "    # por lo que se transponen las dos últimas dimensiones de K\n",
        "    # QK: [m * n_cabezas, l, l]\n",
        "    QK = th.bmm(Q, K.transpose(1, 2))\n",
        "\n",
        "    # se escalan los valores QK\n",
        "    QK_esc = QK / th.math.sqrt(d_k)\n",
        "\n",
        "    if self.masc:\n",
        "      # Creamos una matriz triangular superior binaria (excluyendo la diagonal)\n",
        "      masc = th.triu(th.ones((l, l), dtype = th.bool, device = Q.device),\n",
        "                    diagonal = 1)\n",
        "      # Ponemos los valores de QK_esc en los que la máscara sea 1 a -inf\n",
        "      QK_esc = QK_esc.masked_fill_(masc, -th.inf)\n",
        "\n",
        "    # mapas de atención: [m * n_cabezas, l, l] -> [m * n_cabezas, l, l]\n",
        "    alfas = nn.functional.softmax(QK_esc, dim=-1)\n",
        "    alfas = self.dropout(alfas) # Se agrega dropout de acuerdo al codigo de nanoGPT\n",
        "\n",
        "    # vectores de salida y\n",
        "    # alfas: [m * n_cabezas, l, l], V: [m * n_cabezas, l, d_v]\n",
        "    # Y: [m * n_cabezas, l, d_v]\n",
        "    Y = th.bmm(alfas, V)\n",
        "\n",
        "    # Cambiamos la forma: [m * n_cabezas, l, d_v] -> [m, n_cabezas, l, d_v]\n",
        "    Y = Y.reshape(m, n_cabezas, l, d_v)\n",
        "\n",
        "    # Cambiamos la forma: [m * n_cabezas, l, l] -> [m, n_cabezas, l, l]\n",
        "    alfas = alfas.reshape(m, n_cabezas, l, l)\n",
        "\n",
        "    return Y, alfas\n",
        "\n",
        "\n",
        "class AtencionMulticabeza(nn.Module):\n",
        "  def __init__(self,\n",
        "               d_modelo,\n",
        "               n_cabezas,\n",
        "               p_dropout = 0.0,\n",
        "               masc = False):\n",
        "    super(AtencionMulticabeza, self).__init__()\n",
        "\n",
        "    self.n_cabezas = n_cabezas\n",
        "    self.d_modelo = d_modelo\n",
        "\n",
        "    self.d_cabezas = self.d_modelo // self.n_cabezas\n",
        "\n",
        "    self.ppe = ProductoPuntoEscalado(p_dropout=p_dropout, masc = masc)\n",
        "    self.proy_Q = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "    self.proy_K = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "    self.proy_V = nn.Linear(self.d_modelo, self.d_modelo, bias = False)\n",
        "    self.proy_sal = nn.Linear(self.d_modelo, self.d_modelo)\n",
        "\n",
        "  def forward(self, x):\n",
        "    m, l, d_modelo = x.shape\n",
        "\n",
        "    # Cambiamos la forma del tensor x\n",
        "    # [m, l, d_modelo] -> [m * l, d_modelo]\n",
        "    x = x.reshape(m * l, d_modelo)\n",
        "\n",
        "    # Proyectamos vectores en x a Q, K, V\n",
        "    # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "    Q = self.proy_Q(x)\n",
        "    K = self.proy_K(x)\n",
        "    V = self.proy_V(x)\n",
        "\n",
        "    # Cambiamos la forma: [m * l, d_modelo] -> [m, l, n_cabezas, d_k]\n",
        "    # d_k = d_v = self.d_modelo // self.n_cabezas\n",
        "    Q = Q.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "    K = K.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "    V = V.reshape(m, l, self.n_cabezas, self.d_cabezas)\n",
        "\n",
        "    # Transponemos el eje de las cabezas a la segunda posición del tensor y\n",
        "    # creamos copia (con .contiguous()) para que esté almacenado en memoria de\n",
        "    # forma contigua (.transpose() hace que ya no sea así).\n",
        "    # [m, l, n_cabezas, d_k] -> [m, n_cabezas, l, d_k]\n",
        "    Q = Q.transpose(1, 2).contiguous()\n",
        "    K = K.transpose(1, 2).contiguous()\n",
        "    V = V.transpose(1, 2).contiguous()\n",
        "\n",
        "    # Calculamos el producto punto escalado con Q, K y V\n",
        "    # Q, K: [m, n_cabezas, l, d_k], V:[m, n_cabezas, l, d_v]\n",
        "    # Y: [m, n_cabezas, l, d_v], alfas: [m, n_cabezas, l, l]\n",
        "    Y, alfas = self.ppe(Q, K, V)\n",
        "\n",
        "    # Transponermos el eje de cabezas a la penúltima posición:\n",
        "    # [m, n_cabezas, l, d_k] -> [m, l, n_cabezas, d_k]\n",
        "    Y = Y.transpose(1, 2).contiguous()\n",
        "\n",
        "    # Concatemanos los vectores de todas las cabezas en un solo vector\n",
        "    # [m, l, n_cabezas, d_k] -> [m * l, d_modelo]\n",
        "    # d_modelo = n_cabezas * d_k\n",
        "    Y = Y.reshape(m * l, self.d_modelo)\n",
        "\n",
        "    # Proyectamos la vectores concatenados para obtener la salida\n",
        "    # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "    Y = self.proy_sal(Y)\n",
        "\n",
        "    # Concatemanos los vectores de todas las cabezas en un solo vector\n",
        "    # [m * l, d_modelo] -> [m, l, d_modelo]\n",
        "    Y = Y.reshape(m, l, self.d_modelo)\n",
        "\n",
        "    return Y, alfas\n",
        "\n",
        "class RedDensaPosicion(nn.Module):\n",
        "  def __init__(self,\n",
        "               d_modelo,\n",
        "               d_ff):\n",
        "    super(RedDensaPosicion, self).__init__()\n",
        "    self.d_modelo = d_modelo\n",
        "    self.d_ff = self.d_ff = d_ff if d_ff else 4*d_modelo\n",
        "    self.densa1 = nn.Linear(self.d_modelo, self.d_ff)\n",
        "    self.densa2 = nn.Linear(self.d_ff, self.d_modelo)\n",
        "\n",
        "  def forward(self, x):\n",
        "    m, l, d_modelo = x.shape\n",
        "\n",
        "    # Cambiamos la forma: [m, l, d_modelo] -> [m * l, d_modelo]\n",
        "    x = x.reshape(m * l, d_modelo)\n",
        "\n",
        "    # Pasamos el tensor redimensionado por la red densa\n",
        "    # [m * l, d_modelo] -> [m * l, d_modelo]\n",
        "    x = self.densa1(x)\n",
        "    x = nn.functional.gelu(x)\n",
        "    x = self.densa2(x)\n",
        "\n",
        "    # Lo regresamos a su forma original\n",
        "    # [m * l, d_modelo] -> [m, l, d_modelo]\n",
        "    x = x.reshape(m, l, d_modelo)\n",
        "\n",
        "    return x\n",
        "\n",
        "class BloqueTransformer(nn.Module):\n",
        "  def __init__(self,\n",
        "               d_modelo,\n",
        "               n_cabezas,\n",
        "               d_rdp=None,\n",
        "               p_dropout = 0.1,\n",
        "              masc = False):\n",
        "    super(BloqueTransformer, self).__init__()\n",
        "    self.amc = AtencionMulticabeza(d_modelo = d_modelo,\n",
        "                                  n_cabezas = n_cabezas,\n",
        "                                  p_dropout = p_dropout,\n",
        "                                  masc = masc)\n",
        "    self.norm1 = nn.LayerNorm(d_modelo)\n",
        "    self.rp = RedDensaPosicion(d_modelo, d_rdp)\n",
        "    self.norm2 = nn.LayerNorm(d_modelo)\n",
        "    self.dropout1 = nn.Dropout(p_dropout)\n",
        "    self.dropout2 = nn.Dropout(p_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    salidas_amc, alfas = self.amc(x)\n",
        "    salidas_amc = self.dropout1(salidas_amc)\n",
        "    salidas_amc = self.norm1(x + salidas_amc)\n",
        "\n",
        "    salidas_rp = self.rp(salidas_amc)\n",
        "    salidas_rp = self.dropout2(salidas_rp)\n",
        "\n",
        "    return self.norm2(salidas_amc + salidas_rp)\n",
        "\n",
        "\n",
        "class CodificacionPosicional(nn.Module):\n",
        "  def __init__(self,\n",
        "               maxsec,\n",
        "               d_modelo,\n",
        "               p_dropout = 0.1):\n",
        "    super(CodificacionPosicional, self).__init__()\n",
        "\n",
        "    self.maxsec = maxsec\n",
        "    self.d_modelo = d_modelo\n",
        "\n",
        "    cod_pos = th.zeros((self.maxsec, self.d_modelo))\n",
        "\n",
        "    # Creamos tensor con valores pares 0, 2, 4, ...\n",
        "    # i: [d_modelo // 2, 1]\n",
        "    i = th.arange(0, self.d_modelo, 2, dtype=th.float).reshape(-1, 1)\n",
        "\n",
        "    # Creamos tensor de posiciones 0, 1, ...\n",
        "    # pos: [maxsec, 1]\n",
        "    pos = th.arange(0, self.maxsec, dtype=th.float).reshape(-1, 1)\n",
        "    a = 1.0 / 10000**(i / self.d_modelo)\n",
        "\n",
        "    # grados: [maxsec, d_modelo // 2]\n",
        "    grados = pos @ a.T\n",
        "\n",
        "    cod_pos[:, 0::2] = th.sin(grados) # Para pares\n",
        "    cod_pos[:, 1::2] = th.cos(grados) # Para impares\n",
        "\n",
        "    # Registramos tensor de codificación posicional\n",
        "    self.register_buffer('cod_pos', cod_pos)\n",
        "\n",
        "    self.dropout = nn.Dropout(p_dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    m, l, d_modelo = x.shape\n",
        "    return x + self.cod_pos[:l, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiTLidp2bIA_"
      },
      "source": [
        "## 6. Modelo GPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4HBDnWxbIA_"
      },
      "outputs": [],
      "source": [
        "class nanoGPT(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # lookup table para obtener vectores densos para cada token de la oracion\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "    # obtener y sumar el embedding posicional\n",
        "    self.position_embedding = CodificacionPosicional(context_size, n_embd)\n",
        "    # agregar n_layer bloques transformer enmascarados, con n_cabezas cada uno\n",
        "    self.blocks = nn.Sequential(*[BloqueTransformer(n_embd, n_cabezas=n_head, p_dropout=dropout, masc=True) for _ in range(n_layer)])\n",
        "    # al final de todos los bloques transformers se agrega una capa de normalizacion\n",
        "    self.ln_f = nn.LayerNorm(n_embd)\n",
        "    # capa densa para mapear de dimension n_embd a todo el vocabulario\n",
        "    self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    # B -> Batch (M)\n",
        "    # T -> Time (L)\n",
        "    # C -> Channels (D)\n",
        "    B, T = idx.shape\n",
        "\n",
        "    # idx y targets son ambos tensores de enteros de dimension (B,T)\n",
        "    tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "    x = self.position_embedding(tok_emb) # (B,T,C)\n",
        "    x = self.blocks(x) # (B,T,C)\n",
        "    x = self.ln_f(x) # (B,T,C)\n",
        "    logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "    # cuando se genera texto, no hay targets y no hay perdida\n",
        "    # cuando se entrena, hay targets y se calcula perdida\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      # se adaptan logits y targets pues F.cross_entropy espera un tensor 2D\n",
        "      logits = logits.view(B*T, C)\n",
        "      targets = targets.view(B*T)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_new_tokens):\n",
        "    # idx es un arreglo de indices de dimensiones (B, T)\n",
        "    for _ in range(max_new_tokens):\n",
        "      # recortar idx para tomar como contexto solo tokens hasta context_size\n",
        "      idx_cond = idx[:, -context_size:]\n",
        "      # obtener predicciones, la perdida es ignorada\n",
        "      logits, loss = self(idx_cond)\n",
        "      # tomar el logit del ultimo token\n",
        "      logits = logits[:, -1, :] # (B, T, C) -> (B, C)\n",
        "      # obtener las probabilidades de la siguiente palabra\n",
        "      probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "      # muestrear la predicción a partir de la distribucion dada por softmax\n",
        "      idx_next = th.multinomial(probs, num_samples=1) # (B, 1)\n",
        "      # agregar prediccion al final de idx\n",
        "      idx = th.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "\n",
        "    return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX7Zx6Kfda62"
      },
      "outputs": [],
      "source": [
        "# Durante el entrenamiento, cada (eval_interval) pasos, se obtienen\n",
        "# (eval_iters) perdidas y se promedian para monitorear el estado del\n",
        "# entrenamiento\n",
        "\n",
        "@th.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = th.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LraIAVtgbIA_"
      },
      "source": [
        "## 7. Instanciar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veiYc5BabIA_",
        "outputId": "200d137c-0ce6-4ee3-adb6-793ad545511c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.207681 M parameters\n"
          ]
        }
      ],
      "source": [
        "model = nanoGPT()\n",
        "m = model.to(device)\n",
        "\n",
        "# imprime el número de parámetros en el modelo\n",
        "print(sum(p.numel() for p in m.parameters()) / 1e6, 'M parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BHq74gCbIA_"
      },
      "source": [
        "### 7.1 Ejemplo de generación sin entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zylxj1LIbIBA",
        "outputId": "f5635ca8-6e1e-474c-e132-157ff0f87370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ,MscPDW?yInZp hSdZ?$OnjBLK,VMOgnrEDcS-K-lq&I$pISOKhKWsE-yMj&KoK;w;s-!:r'SeFXLM&3h$ql&CNvHlVEJsXNa3 EQz-- gBD3Q;:$XIwRHJKpAcM-VGyzG\n",
            "nwFm,3yK3DsrJxIu-x?!N'\n",
            "aFyxRLHznXTz;zW.LaZU \n",
            "ZwjKxpJdAUS.&,aCXuKDwjGwDCNWxUrFaFL,TRXS, eNua.IY'\n",
            "SuZXC.arIjQUPQ3u&o -,V!ujIAJoBJFd\n",
            "wKTdN$MEwxPxD$uVTPgXqYjn&.!VP?EMHaKu;YmYU?I$mQxDCS;vxF.QzpU'dq!hDW'Q$YM,MVqpht-'zfSeX;JIlICZDAO$b\n",
            "EfsO-awrWBswFkuaOVJwb;!u33RM.W!Eg;X$KG&hlYVpEV,:DwEYKaZK;$3zCCzCvuIIt-bh.LBHPV'l$hkIe?H-zDK!A ZrY-YR.v3Z.y!-SqQugZZ&'f.hwSuVFljcQF$33$wWxGW'W? mAWNgeu'wBC3hZuPC&GsAI--AFSMh-PgfzHhy:A.\n",
            "nUjM;OLAkx.E:&-gh!hMK:v&IQtIIXcftzNEnHfP'mpo$R IQV$gzEJKNPI;ud?WVE\n",
            "IyzGclvC3C&'ZCSQ.b uhE VCpufzCHNnWzuBEAgZIAHKpHhr'Lrj.WrHjL'n?PEVm\n",
            "SeCTtQaHbL;IuvuKEUn3uEwzwmX!Vpk-&VqRa&dj.Wpe,wj$wlYC:V'KQ3mees.cAW,ZV:wMzXM-RIjifm$s OeZKj;fciyazX$,-u-.xCToLjp?qEMDuBe3y.IQf;zYUZGXB;e.K,SC3y.md$nKJV'bDQuzNuVDA,.VneM'ELC&3BuglTun YSJKgsXjSWVr-DICCe$MQwI;!zvJ,puDAKSRCCPC'YDfKruSQK'EnZTK!yz;EISdBpKBV3BdzntwfPS3QajKoep,Iizgjs-.UnGs;IWGr\n",
            "bw.3yu!QKXuCSf'?&x\n",
            ";JLYgbDKkMbSLJ?-IRc!!Y$hXCdYJ pAmoAXA. uM\n",
            "YhAqfh$;Yvti'w.shblSkCXJ PzFjBhCDbNanru'&RAYzxhha3;ceMCSVCyKQ&nyhPIat ,pva&JEC3QQ3W?JXCQ nE?s,RL.KX\n",
            "jKz&'vz&IpINhECaQ3nBSCthtZhy;PGmw-'CzSrSmyVaKQB?zCoyQ3UyaeXIuvWWWXlX\n",
            "l$IX!MOA.MXMZFi .tZC\n",
            "r$aBKqN-DI-au?Zd\n",
            "ItPWCiOzqsKIbs.W.ciM!Z;R!BAPFSKD$,lx?bms-Nu\n",
            "3U;uIE!IPXiE.zXPujMgMYvKG,KB.:myMdDShK'YaYa3'zN, ;dC3BKho-fZDNN&-3T-HXqrFZf\n",
            "SYWT3LhC&M.$lKIK'Win&SXg$Zp',PrQEBt.WkCMYygZD'Io&T3sK.A,U3Cfzu. Q3rE .cRSW?U'jRTWJ&E;YxSF&tkX-UGyWWv,;l-ZDBh-z,3K;YtZfYZh$YE.fLQt:W!uImQN\n",
            "3q!Q\n",
            "pLuGHXI;.B,OFnHBOoQ3yDOI-AQSToXWI$x-!-IXmsbrY!GtEaQ3vKDILxE,jHWuGzWEJv!mgf?$MKiRjvnH JDSfBtyZVg!aC\n",
            "vz&-AV&gr:VET'spAEsbU.aQT&3B;:?tOjzE&MKP?aHHYIdd.'E  oKWaFzXdVp-udrR'mYWDDdnGM'gT?LZz.ZKe.gCzKEOQKnVXwNCf!BG.z.unSifY3ru'l?sBpyLWr'zzEhtiA.wJF?CCBKQu!uAXHZVt \n",
            "ySuKSI$Iu;SFHJm-iICZQ-X!SZXSSsNXuFZ?AiMwo?A.sFZFxCoYFRKlQY-oV3XSB;clDM-NqxjNXhSTa.hK3:ifA'$AE$3wZocHo&-IGEInMk-WUsH-VTluIehwUIhu?PhCTJxVNMo-QV!VcibSylGj;p!d!aeg!hCup;RBgzFTDMs&?vajSWW$,Y-kx&,CSS,zDtrKN,hgj-fYBx;c&-lhKApCjY Yt\n",
            "nE?KXSkU'?d.np$Vt&dHJ\n"
          ]
        }
      ],
      "source": [
        "# generar del modelo a partir de una entrada [0]\n",
        "context = th.zeros((1, 1), dtype=th.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgV9XqGObIBA"
      },
      "source": [
        "## 8. Entrenar modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lkPlEY4bIBA",
        "outputId": "36bbf1e5-9316-45e7-9e0e-51eb80bd9447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 4.3965, val loss 4.3943\n",
            "step 500: train loss 2.2594, val loss 2.2686\n",
            "step 1000: train loss 2.0808, val loss 2.1274\n",
            "step 1500: train loss 1.9899, val loss 2.0594\n",
            "step 2000: train loss 1.9138, val loss 2.0134\n",
            "step 2500: train loss 1.8722, val loss 1.9907\n",
            "step 3000: train loss 1.8200, val loss 1.9369\n",
            "step 3500: train loss 1.7899, val loss 1.9242\n",
            "step 4000: train loss 1.7717, val loss 1.9250\n",
            "step 4500: train loss 1.7393, val loss 1.8868\n",
            "step 5000: train loss 1.7361, val loss 1.8780\n",
            "step 5500: train loss 1.7094, val loss 1.8729\n",
            "step 6000: train loss 1.6886, val loss 1.8501\n",
            "step 6500: train loss 1.6965, val loss 1.8424\n",
            "step 7000: train loss 1.6856, val loss 1.8540\n",
            "step 7500: train loss 1.6688, val loss 1.8205\n",
            "step 8000: train loss 1.6620, val loss 1.8291\n",
            "step 8500: train loss 1.6504, val loss 1.8185\n",
            "step 9000: train loss 1.6493, val loss 1.8228\n",
            "step 9500: train loss 1.6389, val loss 1.8078\n",
            "step 10000: train loss 1.6375, val loss 1.7941\n",
            "step 10500: train loss 1.6304, val loss 1.8210\n",
            "step 11000: train loss 1.6307, val loss 1.7967\n",
            "step 11500: train loss 1.6180, val loss 1.7926\n",
            "step 12000: train loss 1.6256, val loss 1.7850\n",
            "step 12500: train loss 1.6067, val loss 1.7890\n",
            "step 13000: train loss 1.6129, val loss 1.7789\n",
            "step 13500: train loss 1.6079, val loss 1.7740\n",
            "step 14000: train loss 1.6025, val loss 1.7849\n",
            "step 14500: train loss 1.5957, val loss 1.7779\n",
            "step 15000: train loss 1.6081, val loss 1.7681\n",
            "step 15500: train loss 1.5860, val loss 1.7779\n",
            "step 16000: train loss 1.5924, val loss 1.7866\n",
            "step 16500: train loss 1.5843, val loss 1.7572\n",
            "step 17000: train loss 1.5817, val loss 1.7524\n",
            "step 17500: train loss 1.5920, val loss 1.7663\n",
            "step 18000: train loss 1.5815, val loss 1.7725\n",
            "step 18500: train loss 1.5791, val loss 1.7663\n",
            "step 19000: train loss 1.5721, val loss 1.7385\n",
            "step 19500: train loss 1.5742, val loss 1.7403\n",
            "step 20000: train loss 1.5756, val loss 1.7495\n",
            "step 20500: train loss 1.5791, val loss 1.7463\n",
            "step 21000: train loss 1.5612, val loss 1.7562\n",
            "step 21500: train loss 1.5671, val loss 1.7438\n",
            "step 22000: train loss 1.5658, val loss 1.7456\n",
            "step 22500: train loss 1.5587, val loss 1.7467\n",
            "step 23000: train loss 1.5604, val loss 1.7449\n",
            "step 23500: train loss 1.5473, val loss 1.7202\n",
            "step 24000: train loss 1.5576, val loss 1.7339\n",
            "step 24500: train loss 1.5472, val loss 1.7434\n",
            "step 25000: train loss 1.5557, val loss 1.7376\n",
            "step 25500: train loss 1.5539, val loss 1.7383\n",
            "step 26000: train loss 1.5486, val loss 1.7304\n",
            "step 26500: train loss 1.5451, val loss 1.7391\n",
            "step 27000: train loss 1.5580, val loss 1.7404\n",
            "step 27500: train loss 1.5535, val loss 1.7471\n",
            "step 28000: train loss 1.5565, val loss 1.7376\n",
            "step 28500: train loss 1.5525, val loss 1.7240\n",
            "step 29000: train loss 1.5416, val loss 1.7161\n",
            "step 29500: train loss 1.5404, val loss 1.7235\n",
            "step 30000: train loss 1.5372, val loss 1.7289\n",
            "step 30500: train loss 1.5360, val loss 1.7251\n",
            "step 31000: train loss 1.5321, val loss 1.7436\n",
            "step 31500: train loss 1.5467, val loss 1.7262\n",
            "step 32000: train loss 1.5332, val loss 1.7119\n",
            "step 32500: train loss 1.5360, val loss 1.7227\n",
            "step 33000: train loss 1.5393, val loss 1.7239\n",
            "step 33500: train loss 1.5394, val loss 1.7193\n",
            "step 34000: train loss 1.5345, val loss 1.7197\n",
            "step 34500: train loss 1.5370, val loss 1.7251\n",
            "step 35000: train loss 1.5350, val loss 1.7344\n",
            "step 35500: train loss 1.5316, val loss 1.7213\n",
            "step 36000: train loss 1.5328, val loss 1.7008\n",
            "step 36500: train loss 1.5348, val loss 1.7186\n",
            "step 37000: train loss 1.5221, val loss 1.7128\n",
            "step 37500: train loss 1.5339, val loss 1.7002\n",
            "step 38000: train loss 1.5196, val loss 1.6999\n",
            "step 38500: train loss 1.5294, val loss 1.7087\n",
            "step 39000: train loss 1.5152, val loss 1.7053\n",
            "step 39500: train loss 1.5206, val loss 1.7003\n",
            "step 40000: train loss 1.5192, val loss 1.7216\n",
            "step 40500: train loss 1.5249, val loss 1.6962\n",
            "step 41000: train loss 1.5229, val loss 1.7106\n",
            "step 41500: train loss 1.5233, val loss 1.7179\n",
            "step 42000: train loss 1.5352, val loss 1.7100\n",
            "step 42500: train loss 1.5361, val loss 1.7174\n",
            "step 43000: train loss 1.5232, val loss 1.7113\n",
            "step 43500: train loss 1.5279, val loss 1.7014\n",
            "step 44000: train loss 1.5242, val loss 1.7142\n",
            "step 44500: train loss 1.5081, val loss 1.7089\n",
            "step 45000: train loss 1.5156, val loss 1.7098\n",
            "step 45500: train loss 1.5193, val loss 1.6997\n",
            "step 46000: train loss 1.5180, val loss 1.7090\n",
            "step 46500: train loss 1.5081, val loss 1.7150\n",
            "step 47000: train loss 1.5162, val loss 1.7002\n",
            "step 47500: train loss 1.5246, val loss 1.7001\n",
            "step 48000: train loss 1.5200, val loss 1.7104\n",
            "step 48500: train loss 1.5079, val loss 1.6806\n",
            "step 49000: train loss 1.5186, val loss 1.6956\n",
            "step 49500: train loss 1.5156, val loss 1.6827\n",
            "step 49999: train loss 1.5157, val loss 1.7012\n"
          ]
        }
      ],
      "source": [
        "# crear optimizador\n",
        "optimizer = th.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "  # calcular la perdida cada eval_interval\n",
        "  if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  # generar lote\n",
        "  xb, yb = get_batch('train')\n",
        "\n",
        "  # paso\n",
        "  logits, loss = model(xb, yb)\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXAqZ1DUbIBA"
      },
      "source": [
        "### 8.1 Ejemplo de generación con modelo entrenado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEaAdCKKbIBA",
        "outputId": "4c2bd83d-c278-4020-a797-61ecdb80b605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " is Lucudy\n",
            "As dead, my brave trength,\n",
            "And a yourioarder Tybarl like a pelire blown, minars as a lefbel comes young.\n",
            "\n",
            "KING LIAR Fror:\n",
            "Nor her st, I but beckerguion.\n",
            "\n",
            "ROMEO:\n",
            "The heard, A bond; the indegive one heldly, go,\n",
            "Like our Dercutch revenger discome;\n",
            "I would be astoring\n",
            "ast fiery sweet on king:-\n",
            "Trose now indewers him, a I will boy: that! We well she other;\n",
            "Antmown thou srow the grant Rome,\n",
            "Londior coppemot me adfort, deaking with thy sed;\n",
            "I am spent, burnle seasious time,\n",
            "now in here ent plinces you from against ny more languirs for in the donerion;\n",
            "Qil Liven, cund the ganiouss and I\n",
            "wanching me poor his redols, go conquests:\n",
            "Thee you am now, Carsiss couns yet shall speak not his been their head:\n",
            "Made some, pried\n",
            "and audied thine sic! when, that face it somties!\n",
            "I was he gave man.\n",
            "O, my EDWARD:\n",
            "And good weet of their heard, cords Viry,\n",
            "Thou candingby tongue unwon\n",
            "her sotle sendier's exter, hope, I not pomport.\n",
            "\n",
            "KING RGOLOUCESTER:\n",
            "What, us becall's newing\n",
            "Nor walking and untongeal my either drunks\n",
            "Clowner, and I make, if thou dambrator toing me\n",
            "Your withnessigf,\n",
            "I'll I'll thy name, good louds and hols,\n",
            "And my oldoke to grace come her dime since.\n",
            "\n",
            "ANGELOIUS:\n",
            "O, buse sheep, and would tenleman\n",
            "Haver his griew'st him; bear and frar\n",
            "then duty, my lord.\n",
            "\n",
            "SINLE:\n",
            "I gone it woulds, Londingg weetn knee;\n",
            "You thou Romeo my trict! Have pintutiue were with me the lifter they quitage the\n",
            "That harm, and evermy in himsallys of thousay will seet she Shalow one sty king;\n",
            "Not spawlent Camisting leave innock?\n",
            "\n",
            "LORD KING EDWARD IV:\n",
            "Or, nor\n",
            "feax Vauns: you he are of alth him.\n",
            "\n",
            "First Murdere's poors: from retch amanded thou,\n",
            "Shall not to thee tears\n",
            "in tound thysellance? are entilliaying by resh and you, were more tongue,\n",
            "Loverns that was thine to-die.\n",
            "\n",
            "QUEEN MARLEN:\n",
            "The very some, Upo-mormity!\n",
            "\n",
            "Secont Servingman:\n",
            "I can abch, boar to seark be dival dister!\n",
            "\n",
            "SILLY:\n",
            "I have loves youlds, as not, Englal breather!\n",
            "From are majes; whe bear here speache alseans\n",
            "And wound he's greath, our mils,\n"
          ]
        }
      ],
      "source": [
        "# generar del modelo a partir de una entrada [0]\n",
        "context = th.zeros((1, 1), dtype=th.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}