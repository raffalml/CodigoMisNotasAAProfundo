{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/2026-1/notebooks/0b_autodiff_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Diferenciación automática\n",
        "La [diferenciación automática](https://en.wikipedia.org/wiki/Automatic_differentiation) es un método para evaluar derivadas de funciones representadas como programas [[Automatic Differentiation in Machine Learning: a Survey, Baydin et. al, 2018](https://arxiv.org/abs/1502.05767)].\n",
        "\n",
        "![Diferenciación automática](https://gowrishankar.info/blog/automatic-differentiation-using-gradient-tapes/auto_diff.png)\n",
        "\n",
        "Fuente: [Automatic Differentiation in Machine Learning: a Survey, Baydin et. al, 2018](https://arxiv.org/abs/1502.05767)."
      ],
      "metadata": {
        "id": "4tx-1XjsIRQM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iVsEjrKqxoo9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch as th\n",
        "from torch import nn\n",
        "\n",
        "th.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase `Parameter`\n",
        "La clase [`Parameter`](https://www.tensorflow.org/api_docs/python/tf/Variable) del módulo `nn` de PyTorch define una subclase de `Tensor` que se emplea comúnmente para representar los parámetros que modifican los algoritmos de aprendizaje para generar un modelo. Las instancias de `Parameter` que se definen dentro de una subclase de `Module` del módulo de `nn` se agregan a su lista de parámetros a optimizar.\n",
        "\n",
        "El constructor de la clase `Parameter` recibe un tensor como argumento con el que se crea la instancia.\n"
      ],
      "metadata": {
        "id": "0ZoBbTML6Vqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(nn.parameter.Parameter(th.zeros((10,5))))\n",
        "print(nn.parameter.Parameter(th.rand((10,5))))\n",
        "print(nn.parameter.Parameter(th.ones((5,5))))\n",
        "print(nn.parameter.Parameter(th.tensor([[1.0, 2.0], [3.0, 4.0]])))"
      ],
      "metadata": {
        "id": "ppRAmedE8zFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089a4bca-497c-4974-98da-d81aa91c85ad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593, 0.3904],\n",
            "        [0.6009, 0.2566, 0.7936, 0.9408, 0.1332],\n",
            "        [0.9346, 0.5936, 0.8694, 0.5677, 0.7411],\n",
            "        [0.4294, 0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317, 0.1053],\n",
            "        [0.2695, 0.3588, 0.1994, 0.5472, 0.0062],\n",
            "        [0.9516, 0.0753, 0.8860, 0.5832, 0.3376],\n",
            "        [0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
            "        [0.6343, 0.3644, 0.7104, 0.9464, 0.7890],\n",
            "        [0.2814, 0.7886, 0.5895, 0.7539, 0.1952]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos realizar cualquier operación tensorial con una instancia de `Parameter`, ya sea con otras instancias de `Parameter` o `Tensor`. El resultado de la operación es una instancia de `Tensor`."
      ],
      "metadata": {
        "id": "9nBPiInUJ1nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = nn.parameter.Parameter(th.zeros(10, 5))\n",
        "\n",
        "print(param.T)\n",
        "print(param + th.ones_like(param))\n",
        "print(param * th.zeros_like(param))\n",
        "print(param @ th.rand((5, 10)))"
      ],
      "metadata": {
        "id": "3YtbOBKYKWYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adaf11a-b82b-4eb3-e78f-8fb075d49eba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<PermuteBackward0>)\n",
            "tensor([[1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.]], grad_fn=<AddBackward0>)\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.]], grad_fn=<MulBackward0>)\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Diferenciación automática en PyTorch\n",
        "PyTorch puede diferenciar automáticamente secuencias de operaciones con instancias de `Tensor` o `Parameter`. Para ello se mantiene una gráfica de cómputo, la cual se va generando de manera dinámica conforme se ejecutan operaciones con instancias que tienen la propiedad `requires_grad` en verdadero (solo ten cuidado con las operaciones _in-place_). Por defecto, todas las instancias de `Parameter` tienen esta propiedad en verdadero y las instancias de `Tensor` en falso."
      ],
      "metadata": {
        "id": "KNsBnBVfYQln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(param.requires_grad)"
      ],
      "metadata": {
        "id": "D8gRZPnJYTqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4b9e18-0096-45e5-fbdc-16d44de08e52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ten = th.zeros((10, 5))\n",
        "\n",
        "print(ten.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bftZoHgJWopo",
        "outputId": "680851a4-9164-4611-ffc3-78e3496fddb2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es posible cambiar el valor de esta propiedad en una instancia usando el método `requires_grad_` (_in-place_)."
      ],
      "metadata": {
        "id": "YFjSw0bpcY4V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param.requires_grad_(False)\n",
        "ten.requires_grad_(True)\n",
        "print(ten.requires_grad, param.requires_grad)"
      ],
      "metadata": {
        "id": "npCReZQwc6Qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344357f4-1de2-4b80-bf35-c9316db9011c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param.T, ten.T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxw4HukKXaCv",
        "outputId": "e7f55f34-fbbe-4d6f-f050-01b8278d4267"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
              " tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], grad_fn=<PermuteBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9DBfyVuXrWP",
        "outputId": "19772e70-bf0c-4aed-9f5f-43cc801be860"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para modificar el contenido de una instancia de `Parameter` es necesario especificar que no se registre la operación usando el ámbito `no_grad`."
      ],
      "metadata": {
        "id": "uvmThL4IIoJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with th.no_grad():\n",
        "  param[0, 0] = 1"
      ],
      "metadata": {
        "id": "F91sInvJI3n7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JX_1CtWZYBE_",
        "outputId": "f1ef42ab-594a-4a6d-82f9-3440f7ef72bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0.]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En general, existen métodos para instancias tanto de `Parameter` como de `Tensor` que modifican el contenido _in-place_. Los nombres de estos métodos usualmente terminan con un guión bajo. Tal es el caso de `add_` y `mul_`, que suman y multiplican un tensor. Debido a que estas operaciones no deben registrarse cuando las instancias de `Parameter` o `Tensor` tienen `requires_grad = True`, las ejecutamos dentro del ámbito `no_grad`."
      ],
      "metadata": {
        "id": "bTyVfg2Q9QmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with th.no_grad():\n",
        "  param.add_(th.ones_like(param))\n",
        "  param.mul_(-th.ones_like(param))\n",
        "  param.sub_(2 * th.ones_like(param))\n",
        "print(param)"
      ],
      "metadata": {
        "id": "iyktgZWhbyir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e62afe3-b6d0-4f8e-befc-a5d18fe408aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-4., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.],\n",
            "        [-3., -3., -3., -3., -3.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para obtener el gradiente de una [función escalar](https://en.wiktionary.org/wiki/scalar_function) respecto a un tensor que está siendo contemplado se debe llamar al método `backward`.\n",
        "\n",
        "Por ejemplo, considera la siguiente función:\n",
        "\n",
        "$$\n",
        "f(x, y) = 2x^3 + 3y^2 + c\n",
        "$$\n",
        "\n",
        "![](https://camo.githubusercontent.com/32e5a6b4cf8ad981ba5b19c9a5fab02fdc14d409237f774034d23536a731ae5c/68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f626572656d6c2f6961702f6d61737465722f6669672f6175746f646966665f6578616d706c652e737667)\n",
        "\n",
        "Ejemplo y figura de Berenice Montalvo-Lezama y Ricardo Montalvo-Lezama (tomado de [https://github.com/gibranfp/CursoAprendizajeProfundo/blob/2022-1/notebooks/1c_pytorch.ipynb](https://github.com/gibranfp/CursoAprendizajeProfundo/blob/2022-1/notebooks/1c_pytorch.ipynb)).\n",
        "\n",
        "Evaluando esta función en $x = 2$, $y = 3$ y $c = 1.0$, tenemos\n",
        "\n",
        "$$\n",
        "f(2, 3) = 2\\cdot (2)^3 + 3 \\cdot (3)^2 + 1 = 44\n",
        "$$\n",
        "\n",
        "Las derivadas partiales evaluadas en estos puntos estarían dadas por\n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{\\partial f}{\\partial x} = 6x^2 = 6 \\cdot (2)^2 = 24\\\\\n",
        "\\frac{\\partial f}{\\partial y} = 6y = 6 (3) = 18\n",
        "\\end{align}\n",
        "$$"
      ],
      "metadata": {
        "id": "IC0yKUxFb6CI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = th.tensor(2.0, requires_grad = True)\n",
        "y = th.tensor(3.0, requires_grad = True)\n",
        "c = th.tensor(1.0)\n",
        "\n",
        "f = 2 * x**3 + 3 * y**2 + c"
      ],
      "metadata": {
        "id": "c5USoC1Xdymn"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.backward()"
      ],
      "metadata": {
        "id": "2F-j54InbyVf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se invoca a este método, se calculan los gradientes de la función respecto al tensor correspondiente y se acumulan en el tensor `grad` que es una propiedad de todas las instancia de `Tensor` y `Parameter`."
      ],
      "metadata": {
        "id": "l8cxaru0Z8zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad, y.grad"
      ],
      "metadata": {
        "id": "yw9hDOw0Z-5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea1df6b-3dff-4d75-e169-2f165c50d247"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(24.), tensor(18.))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(c.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efc4VQE0dDbW",
        "outputId": "357ff79d-402e-4c55-eb29-9c718a301b62"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, al construir la gráfica de cómputo de una operación, PyTorch almacena la función de retropropagación correspondiente en la propiedad `grad_fn` del tensor resultante. Para el ejemplo anterior, esta sería:"
      ],
      "metadata": {
        "id": "XWPY5NCnkInN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = x**3\n",
        "b = 2 * a\n",
        "\n",
        "d = y**2\n",
        "e = 3 * d\n",
        "\n",
        "g = b + e\n",
        "f = g + c\n",
        "\n",
        "print(a.grad_fn, b.grad_fn, d.grad_fn, e.grad_fn, g.grad_fn, f.grad_fn)"
      ],
      "metadata": {
        "id": "K3wv_aBmliuo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d2b763-4fe7-4e51-b4b8-0eb9d35ea2aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<PowBackward0 object at 0x7fa55c298b80> <MulBackward0 object at 0x7fa55c298a60> <PowBackward0 object at 0x7fa55c298a90> <MulBackward0 object at 0x7fa55c298ac0> <AddBackward0 object at 0x7fa55c298b20> <AddBackward0 object at 0x7fa55c29a9e0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos evaluar estas funciones:"
      ],
      "metadata": {
        "id": "uWahNo-Pq1xA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad_fn(th.tensor(1.))"
      ],
      "metadata": {
        "id": "lDkD5Lhcq1xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca9948a-76ad-49e4-8ae2-425a51ed36e5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(12., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.grad_fn(th.tensor(1.))"
      ],
      "metadata": {
        "id": "GXNA8YEsVRvA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0402b0-4fe5-452e-b8f4-c91c97770371"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.), None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.grad_fn(b.grad_fn(th.tensor(1.))[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKolVoHhe8t_",
        "outputId": "08c82e36-3163-45cc-8cbc-c857bb06db46"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(24., grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.grad_fn(b.grad_fn(g.grad_fn(f.grad_fn(th.tensor(1.))[0])[0])[0]))\n",
        "print(d.grad_fn(e.grad_fn(g.grad_fn(f.grad_fn(th.tensor(1.))[0])[0])[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLzYjHFCgQYv",
        "outputId": "a5076b1a-a061-4c25-e38a-e038ef403694"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(24., grad_fn=<MulBackward0>)\n",
            "tensor(18., grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se llama al método `backward` se van evaluando las funciones de retropropagación en la gráfica de cómputo desde el último nodo hacia atrás usando la propiedad `next_functions` de `grad_fn` hasta obtener los gradientes de los tensores correspondientes en los nodos hoja. Nota que en algunos casos es necesario mantener los resultados intermedios para poder evaluar esta función y obtener el gradiente correspondiente.\n",
        "\n",
        "Consideremos ahora la función:\n",
        "\n",
        "$$\n",
        "g(\\mathbf{m}) =  \\sum_{j=1}^d m_j^2\n",
        "$$\n",
        "\n",
        "La derivada parcial de esta función respecto a cada elemento de $\\mathbf{m}$ estaría dada por\n",
        "\n",
        "$$\n",
        "\\frac{\\partial g(\\mathbf{m})}{\\partial m_j} = 2\\cdot m_j\n",
        "$$\n",
        "\n",
        "Definimos esta función, la evalúamos para 100 valores entre -10 y 10 y obtenemos las derivadas parciales respecto a cada uno de los 100 valores (gradiente) usando el método `backward`:"
      ],
      "metadata": {
        "id": "RcXGNFw7eUAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = th.linspace(start = -10, end = 10, steps = 100, requires_grad = True)\n",
        "g = (m**2).sum()\n",
        "g.backward()\n",
        "\n",
        "print(g.grad_fn, m, m.grad)"
      ],
      "metadata": {
        "id": "bhGoV0mdevZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2b2743f-e435-4bef-ea85-205ea79396a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SumBackward0 object at 0x7fa55c298550> tensor([-10.0000,  -9.7980,  -9.5960,  -9.3939,  -9.1919,  -8.9899,  -8.7879,\n",
            "         -8.5859,  -8.3838,  -8.1818,  -7.9798,  -7.7778,  -7.5758,  -7.3737,\n",
            "         -7.1717,  -6.9697,  -6.7677,  -6.5657,  -6.3636,  -6.1616,  -5.9596,\n",
            "         -5.7576,  -5.5556,  -5.3535,  -5.1515,  -4.9495,  -4.7475,  -4.5455,\n",
            "         -4.3434,  -4.1414,  -3.9394,  -3.7374,  -3.5354,  -3.3333,  -3.1313,\n",
            "         -2.9293,  -2.7273,  -2.5253,  -2.3232,  -2.1212,  -1.9192,  -1.7172,\n",
            "         -1.5152,  -1.3131,  -1.1111,  -0.9091,  -0.7071,  -0.5051,  -0.3030,\n",
            "         -0.1010,   0.1010,   0.3030,   0.5051,   0.7071,   0.9091,   1.1111,\n",
            "          1.3131,   1.5152,   1.7172,   1.9192,   2.1212,   2.3232,   2.5253,\n",
            "          2.7273,   2.9293,   3.1313,   3.3333,   3.5354,   3.7374,   3.9394,\n",
            "          4.1414,   4.3434,   4.5455,   4.7475,   4.9495,   5.1515,   5.3535,\n",
            "          5.5556,   5.7576,   5.9596,   6.1616,   6.3636,   6.5657,   6.7677,\n",
            "          6.9697,   7.1717,   7.3737,   7.5758,   7.7778,   7.9798,   8.1818,\n",
            "          8.3838,   8.5859,   8.7879,   8.9899,   9.1919,   9.3939,   9.5960,\n",
            "          9.7980,  10.0000], requires_grad=True) tensor([-20.0000, -19.5960, -19.1919, -18.7879, -18.3838, -17.9798, -17.5758,\n",
            "        -17.1717, -16.7677, -16.3636, -15.9596, -15.5556, -15.1515, -14.7475,\n",
            "        -14.3434, -13.9394, -13.5354, -13.1313, -12.7273, -12.3232, -11.9192,\n",
            "        -11.5152, -11.1111, -10.7071, -10.3030,  -9.8990,  -9.4949,  -9.0909,\n",
            "         -8.6869,  -8.2828,  -7.8788,  -7.4747,  -7.0707,  -6.6667,  -6.2626,\n",
            "         -5.8586,  -5.4545,  -5.0505,  -4.6465,  -4.2424,  -3.8384,  -3.4343,\n",
            "         -3.0303,  -2.6263,  -2.2222,  -1.8182,  -1.4141,  -1.0101,  -0.6061,\n",
            "         -0.2020,   0.2020,   0.6061,   1.0101,   1.4141,   1.8182,   2.2222,\n",
            "          2.6263,   3.0303,   3.4343,   3.8384,   4.2424,   4.6465,   5.0505,\n",
            "          5.4545,   5.8586,   6.2626,   6.6667,   7.0707,   7.4747,   7.8788,\n",
            "          8.2828,   8.6869,   9.0909,   9.4949,   9.8990,  10.3030,  10.7071,\n",
            "         11.1111,  11.5152,  11.9192,  12.3232,  12.7273,  13.1313,  13.5354,\n",
            "         13.9394,  14.3434,  14.7475,  15.1515,  15.5556,  15.9596,  16.3636,\n",
            "         16.7677,  17.1717,  17.5758,  17.9798,  18.3838,  18.7879,  19.1919,\n",
            "         19.5960,  20.0000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que se llama al método `.backward`, se elimina el grafo de cómputo. Sin embargo, es posible mantenerlo pasando el argumento `retain_graph=True` en la llamada."
      ],
      "metadata": {
        "id": "5ABAfcxqfeJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = (m**2).sum()\n",
        "g.backward(retain_graph=True)"
      ],
      "metadata": {
        "id": "-qP5SQS3gnEf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.backward()"
      ],
      "metadata": {
        "id": "Vk9bpFcfi7rn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkAlFXVsjI92",
        "outputId": "6bc4757e-76aa-44ed-ba7e-f6641865fa80"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-60.0000, -58.7879, -57.5758, -56.3636, -55.1515, -53.9394, -52.7273,\n",
              "        -51.5152, -50.3030, -49.0909, -47.8788, -46.6667, -45.4545, -44.2424,\n",
              "        -43.0303, -41.8182, -40.6061, -39.3939, -38.1818, -36.9697, -35.7576,\n",
              "        -34.5455, -33.3333, -32.1212, -30.9091, -29.6970, -28.4848, -27.2727,\n",
              "        -26.0606, -24.8485, -23.6364, -22.4242, -21.2121, -20.0000, -18.7879,\n",
              "        -17.5758, -16.3636, -15.1515, -13.9394, -12.7273, -11.5152, -10.3030,\n",
              "         -9.0909,  -7.8788,  -6.6667,  -5.4545,  -4.2424,  -3.0303,  -1.8182,\n",
              "         -0.6061,   0.6061,   1.8182,   3.0303,   4.2424,   5.4545,   6.6667,\n",
              "          7.8788,   9.0909,  10.3030,  11.5152,  12.7273,  13.9394,  15.1515,\n",
              "         16.3636,  17.5758,  18.7879,  20.0000,  21.2121,  22.4242,  23.6364,\n",
              "         24.8485,  26.0606,  27.2727,  28.4848,  29.6970,  30.9091,  32.1212,\n",
              "         33.3333,  34.5455,  35.7576,  36.9697,  38.1818,  39.3939,  40.6061,\n",
              "         41.8182,  43.0303,  44.2424,  45.4545,  46.6667,  47.8788,  49.0909,\n",
              "         50.3030,  51.5152,  52.7273,  53.9394,  55.1515,  56.3636,  57.5758,\n",
              "         58.7879,  60.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Múltiples llamadas a la función y al método `backward` acumulan los gradientes en `.grad`. Por lo mismo, en muchas ocasiones es necesarios ponerlos a 0 con el método (_in-pace_) `zero_`."
      ],
      "metadata": {
        "id": "DxiBlYG8iI4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with th.no_grad():\n",
        "  m.grad.zero_()\n",
        "m.grad"
      ],
      "metadata": {
        "id": "qIGcqWEzf0F4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0320e4-698e-4245-b16a-7ee54cdf5e3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos diferenciar automáticamente respecto a más de un tensor."
      ],
      "metadata": {
        "id": "pz7QElnzxYha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l = th.rand_like(m, requires_grad=True)\n",
        "h = (m**2 + l**3).sum()\n",
        "h.backward()\n",
        "h.grad_fn, m.grad, l.grad"
      ],
      "metadata": {
        "id": "MUaFQOABZnRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5862368-dca2-41cd-ee3e-f9009b2e6fb0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<SumBackward0 at 0x7fa55c298370>,\n",
              " tensor([-20.0000, -19.5960, -19.1919, -18.7879, -18.3838, -17.9798, -17.5758,\n",
              "         -17.1717, -16.7677, -16.3636, -15.9596, -15.5556, -15.1515, -14.7475,\n",
              "         -14.3434, -13.9394, -13.5354, -13.1313, -12.7273, -12.3232, -11.9192,\n",
              "         -11.5152, -11.1111, -10.7071, -10.3030,  -9.8990,  -9.4949,  -9.0909,\n",
              "          -8.6869,  -8.2828,  -7.8788,  -7.4747,  -7.0707,  -6.6667,  -6.2626,\n",
              "          -5.8586,  -5.4545,  -5.0505,  -4.6465,  -4.2424,  -3.8384,  -3.4343,\n",
              "          -3.0303,  -2.6263,  -2.2222,  -1.8182,  -1.4141,  -1.0101,  -0.6061,\n",
              "          -0.2020,   0.2020,   0.6061,   1.0101,   1.4141,   1.8182,   2.2222,\n",
              "           2.6263,   3.0303,   3.4343,   3.8384,   4.2424,   4.6465,   5.0505,\n",
              "           5.4545,   5.8586,   6.2626,   6.6667,   7.0707,   7.4747,   7.8788,\n",
              "           8.2828,   8.6869,   9.0909,   9.4949,   9.8990,  10.3030,  10.7071,\n",
              "          11.1111,  11.5152,  11.9192,  12.3232,  12.7273,  13.1313,  13.5354,\n",
              "          13.9394,  14.3434,  14.7475,  15.1515,  15.5556,  15.9596,  16.3636,\n",
              "          16.7677,  17.1717,  17.5758,  17.9798,  18.3838,  18.7879,  19.1919,\n",
              "          19.5960,  20.0000]),\n",
              " tensor([1.3696e-01, 1.1715e+00, 5.6508e-01, 5.6354e-02, 7.8560e-01, 7.5328e-02,\n",
              "         1.7238e-02, 1.5143e-01, 1.1679e-02, 9.8969e-02, 2.9988e+00, 1.0601e+00,\n",
              "         1.2835e+00, 3.3986e-03, 8.8353e-02, 3.3381e-01, 1.0029e+00, 1.0814e-02,\n",
              "         2.4293e-01, 1.2080e-01, 7.5416e-01, 2.9569e-01, 6.4966e-01, 7.7942e-02,\n",
              "         7.3761e-02, 1.3017e-01, 3.2443e-01, 3.3302e-02, 2.5350e+00, 4.8184e-01,\n",
              "         2.5958e+00, 1.2902e+00, 1.7603e-02, 2.1472e+00, 3.9406e-01, 2.8522e-01,\n",
              "         2.1657e-02, 2.5573e-05, 1.2406e+00, 4.5812e-01, 1.4477e+00, 2.4121e-02,\n",
              "         2.2770e+00, 5.3046e-02, 5.1335e-01, 1.0960e+00, 1.7243e+00, 2.4498e+00,\n",
              "         2.7388e+00, 3.2161e-02, 1.1750e+00, 2.4357e-01, 5.9463e-01, 4.7443e-02,\n",
              "         2.7385e+00, 5.3087e-02, 1.7659e+00, 1.3698e+00, 1.3166e+00, 1.5825e-01,\n",
              "         2.7331e+00, 1.1158e+00, 9.5537e-01, 1.0575e-02, 1.5118e+00, 5.4185e-01,\n",
              "         2.2022e-01, 2.5918e+00, 1.1217e+00, 1.4967e-01, 1.8292e-01, 6.8008e-01,\n",
              "         1.8214e+00, 4.1567e-01, 1.3830e-01, 3.2429e-01, 4.7978e-02, 1.3803e+00,\n",
              "         2.3604e+00, 2.5719e-03, 1.1388e+00, 1.7250e+00, 1.0467e+00, 3.1093e-01,\n",
              "         1.7372e+00, 1.7454e+00, 1.4158e+00, 5.0958e-01, 4.0539e-01, 9.1906e-01,\n",
              "         5.0842e-01, 3.6960e-01, 2.0152e+00, 2.5930e+00, 6.0885e-01, 4.5175e-01,\n",
              "         7.7205e-01, 6.6311e-01, 1.1540e+00, 1.2292e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por otro lado, es posible obtener derivadas de orden mayor, pero esto se logra usando la función `grad` del módulo `autograd` en lugar del método `backward`."
      ],
      "metadata": {
        "id": "3_BvYzBLw4XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = th.rand(100, requires_grad=True)\n",
        "f = (z**3).sum()\n",
        "df = th.autograd.grad(f, z, create_graph=True)[0]\n",
        "d2f = th.autograd.grad(df.sum(), z)[0]\n",
        "\n",
        "print(f, f.grad_fn)\n",
        "print(df, df.grad_fn)\n",
        "print(z, z.grad)\n",
        "print(d2f)"
      ],
      "metadata": {
        "id": "V-0lkQnzZYwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f944185-491e-43d0-d95e-1ddb88b89cae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(20.5570, grad_fn=<SumBackward0>) <SumBackward0 object at 0x7fa55c26f2e0>\n",
            "tensor([6.3126e-03, 2.9859e-01, 2.5451e+00, 1.4481e+00, 6.7725e-01, 1.1826e-01,\n",
            "        1.1302e-01, 8.1484e-03, 3.4075e-01, 1.3421e+00, 2.0114e+00, 1.6024e+00,\n",
            "        1.0102e-02, 1.1918e-01, 5.3195e-01, 2.9028e+00, 9.8268e-01, 4.1184e-01,\n",
            "        1.4989e+00, 2.8748e-01, 9.3321e-02, 2.2444e+00, 2.2301e-01, 4.7944e-01,\n",
            "        2.0247e-05, 2.0898e+00, 2.3170e+00, 1.3963e+00, 6.8732e-02, 1.2792e-04,\n",
            "        2.6458e-02, 2.2856e+00, 1.6430e+00, 2.5434e+00, 1.7416e+00, 1.1777e+00,\n",
            "        7.3538e-01, 4.3018e-02, 1.5386e-02, 3.1348e-03, 1.4897e+00, 1.9434e-01,\n",
            "        4.7850e-01, 1.3515e-01, 5.0157e-01, 6.5785e-02, 9.0091e-02, 1.3301e+00,\n",
            "        3.7045e-01, 1.9618e+00, 3.4598e-01, 5.3240e-02, 5.0869e-01, 1.9911e-01,\n",
            "        3.6129e-01, 1.7283e-03, 1.8240e+00, 6.9219e-02, 1.6934e+00, 1.5851e+00,\n",
            "        2.2045e+00, 4.0699e-02, 2.2167e+00, 2.0849e-01, 1.4099e+00, 2.8201e+00,\n",
            "        5.5337e-01, 7.3844e-01, 4.4441e-01, 2.0423e-02, 1.6426e+00, 3.9772e-05,\n",
            "        1.9702e+00, 2.2922e+00, 2.8393e+00, 4.3791e-01, 2.3859e-02, 1.1252e+00,\n",
            "        1.8075e+00, 1.6506e-05, 4.4817e-01, 1.2033e-01, 6.2454e-01, 1.9339e-01,\n",
            "        2.6217e-01, 3.4940e-01, 1.8523e-03, 2.4857e+00, 2.5346e+00, 5.3315e-01,\n",
            "        5.8890e-01, 2.6274e-01, 7.0476e-03, 5.4092e-04, 1.4111e+00, 1.5252e-01,\n",
            "        9.5653e-02, 6.3753e-01, 3.3366e-01, 3.4322e-01],\n",
            "       grad_fn=<MulBackward0>) <MulBackward0 object at 0x7fa55c298ac0>\n",
            "tensor([0.0459, 0.3155, 0.9211, 0.6948, 0.4751, 0.1985, 0.1941, 0.0521, 0.3370,\n",
            "        0.6689, 0.8188, 0.7308, 0.0580, 0.1993, 0.4211, 0.9837, 0.5723, 0.3705,\n",
            "        0.7069, 0.3096, 0.1764, 0.8649, 0.2726, 0.3998, 0.0026, 0.8346, 0.8788,\n",
            "        0.6822, 0.1514, 0.0065, 0.0939, 0.8729, 0.7401, 0.9208, 0.7619, 0.6265,\n",
            "        0.4951, 0.1197, 0.0716, 0.0323, 0.7047, 0.2545, 0.3994, 0.2122, 0.4089,\n",
            "        0.1481, 0.1733, 0.6659, 0.3514, 0.8087, 0.3396, 0.1332, 0.4118, 0.2576,\n",
            "        0.3470, 0.0240, 0.7797, 0.1519, 0.7513, 0.7269, 0.8572, 0.1165, 0.8596,\n",
            "        0.2636, 0.6855, 0.9696, 0.4295, 0.4961, 0.3849, 0.0825, 0.7400, 0.0036,\n",
            "        0.8104, 0.8741, 0.9729, 0.3821, 0.0892, 0.6124, 0.7762, 0.0023, 0.3865,\n",
            "        0.2003, 0.4563, 0.2539, 0.2956, 0.3413, 0.0248, 0.9103, 0.9192, 0.4216,\n",
            "        0.4431, 0.2959, 0.0485, 0.0134, 0.6858, 0.2255, 0.1786, 0.4610, 0.3335,\n",
            "        0.3382], requires_grad=True) None\n",
            "tensor([0.2752, 1.8929, 5.5264, 4.1687, 2.8508, 1.1913, 1.1646, 0.3127, 2.0221,\n",
            "        4.0131, 4.9129, 4.3851, 0.3482, 1.1959, 2.5266, 5.9020, 3.4340, 2.2231,\n",
            "        4.2411, 1.8574, 1.0582, 5.1897, 1.6359, 2.3986, 0.0156, 5.0078, 5.2729,\n",
            "        4.0933, 0.9082, 0.0392, 0.5635, 5.2371, 4.4403, 5.5245, 4.5716, 3.7593,\n",
            "        2.9706, 0.7185, 0.4297, 0.1940, 4.2281, 1.5271, 2.3962, 1.2735, 2.4533,\n",
            "        0.8885, 1.0398, 3.9951, 2.1084, 4.8520, 2.0376, 0.7993, 2.4707, 1.5458,\n",
            "        2.0822, 0.1440, 4.6785, 0.9114, 4.5079, 4.3614, 5.1433, 0.6988, 5.1576,\n",
            "        1.5817, 4.1132, 5.8173, 2.5769, 2.9768, 2.3093, 0.4950, 4.4397, 0.0218,\n",
            "        4.8624, 5.2447, 5.8371, 2.2924, 0.5351, 3.6745, 4.6573, 0.0141, 2.3190,\n",
            "        1.2016, 2.7376, 1.5234, 1.7737, 2.0476, 0.1491, 5.4615, 5.5150, 2.5294,\n",
            "        2.6584, 1.7756, 0.2908, 0.0806, 4.1150, 1.3529, 1.0714, 2.7659, 2.0010,\n",
            "        2.0294])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neurona artificial\n",
        "La salida de una neurona artificial se obtiene multiplicando la transpuesta del vector columna de pesos $\\mathbf{w}\\in \\mathbb{R}^d$ por el vector columna de entrada $\\mathbf{x} \\in \\mathbb{R}^d$, sumando al final el valor del sesgo $b$ y evaluando el resultado con la función de activación $\\phi$, esto es\n",
        "\n",
        "$$\n",
        "a = \\phi\\left(\\mathbf{w}^\\top \\mathbf{x} + b\\right)\n",
        "$$\n",
        "\n",
        "![Diagrama general de la neurona artificial](http://turing.iimas.unam.mx/~gibranfp/cursos/neurona.svg)\n",
        "\n",
        "Una neurona artificial con función de activación logística o sigmoide entrenada minimizando la [entropía cruzada binaria](https://en.wikipedia.org/wiki/Cross_entropy) se corresponde con una [regresión logística](https://en.wikipedia.org/wiki/Logistic_regression). La [función sigmoide](https://en.wikipedia.org/wiki/Sigmoid_function) o logística está dada por\n",
        "\n",
        "$$\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}},\n",
        "$$\n",
        "\n",
        "Por lo tanto, la salida de la neurona sigmoide o logística sería\n",
        "\n",
        "$$\n",
        "\\hat{y} = \\sigma(\\mathbf{w}^\\top \\mathbf{x} + b)\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "vk9WlAmq7LUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neurona_sigmoide(w, b, X):\n",
        "  return th.sigmoid(X @ w + b)"
      ],
      "metadata": {
        "id": "BzT_ShW3Vaqr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por su parte, la entropía cruzada binaria está dada por\n",
        "$$\n",
        "ECB(\\mathbf{y}, \\mathbf{\\hat{y}}) = -\\sum_{i=1}^n \\left[y^{(i)} \\log{(\\hat{y}^{(i)})} + (1 - y^{(i)}) \\log{(1 - \\hat{y}^{(i)}}\\right]\n",
        "$$"
      ],
      "metadata": {
        "id": "bVrf1MGzWh06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ecb(y, y_hat):\n",
        "  perdida_unos = th.log(y_hat[y == 1]).sum()\n",
        "  perdida_ceros = th.log(1 - y_hat[y == 0]).sum()\n",
        "  return -(perdida_unos + perdida_ceros)"
      ],
      "metadata": {
        "id": "7NhMcpgjxKot"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generamos un conjunto de ejemplos sintéticos (aleatorios)."
      ],
      "metadata": {
        "id": "r8kKCDhfWuCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 100\n",
        "d = 10\n",
        "X = th.normal(size = (n, d), mean = 0, std = 1)\n",
        "y = th.randint(low = 0, high = 2, size = (n, 1))\n",
        "\n",
        "print(X, y)"
      ],
      "metadata": {
        "id": "Ek6GMF5pWtWV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c5c3ada-6838-4a77-df58-9112275c7eef"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-5.5719e-01, -9.6835e-01,  8.7128e-01, -9.5641e-02,  4.0380e-01,\n",
            "         -7.1398e-01,  8.3373e-01, -9.5855e-01,  1.0682e+00, -2.5272e-01],\n",
            "        [-1.8815e-01, -7.7115e-01,  1.7989e-01, -2.1268e+00, -1.3408e-01,\n",
            "         -1.0408e+00,  7.6942e-01,  2.5574e+00,  5.7161e-01,  1.3596e+00],\n",
            "        [ 4.3344e-01, -7.1719e-01,  1.0554e+00, -1.4534e+00,  1.7361e+00,\n",
            "          1.8350e+00,  8.8002e-01,  5.6080e-02,  3.7818e-01,  7.0511e-01],\n",
            "        [-1.7237e+00, -8.4348e-01, -4.8619e-01, -3.3600e-01,  3.6716e-02,\n",
            "          4.9340e-01,  8.8538e-01,  1.8244e-01,  7.8638e-01, -5.7920e-02],\n",
            "        [ 1.3637e-01,  3.0880e-01,  1.6617e+00,  1.7512e-01,  6.0841e-01,\n",
            "          1.6309e+00, -8.4723e-02,  1.0844e+00,  1.9537e-01, -1.3350e+00],\n",
            "        [ 3.9451e-01,  1.7060e+00, -7.9394e-01,  3.7523e-01,  8.7910e-02,\n",
            "         -1.2415e+00, -5.6626e-01,  3.9892e-01,  1.3695e+00, -2.5189e-01],\n",
            "        [ 1.9003e+00,  1.6951e+00,  2.8090e-02, -1.7537e-01,  4.0854e-01,\n",
            "         -1.2609e+00,  9.1652e-01, -2.8006e-02, -2.1844e-01,  1.6630e-01],\n",
            "        [ 2.1442e+00,  1.7046e+00,  1.5460e+00,  5.4476e-01,  9.9346e-01,\n",
            "          5.0667e-01, -1.3969e-01, -1.1808e+00, -1.2829e+00,  4.4849e-01],\n",
            "        [ 4.9029e-01, -4.3747e-01, -1.2201e+00, -5.8542e-01,  6.6637e-01,\n",
            "         -7.4265e-02, -2.0960e-01,  1.6632e-01, -1.8316e+00,  3.5699e-01],\n",
            "        [ 9.1429e-01,  2.1882e+00, -9.8515e-01, -2.4885e+00, -3.3132e-01,\n",
            "          8.4358e-01, -3.1824e-01,  1.2154e+00,  1.4200e+00, -5.4650e-02],\n",
            "        [ 2.4700e-02, -1.0641e+00, -7.6019e-01, -4.0751e-01,  3.1054e-01,\n",
            "          3.7145e-01,  2.6968e-01,  7.8999e-01,  9.4461e-01, -1.5824e+00],\n",
            "        [ 9.8713e-01,  1.1457e+00, -2.7107e+00, -6.1301e-01,  1.3917e+00,\n",
            "          2.2285e-01,  6.8388e-01, -1.3246e+00, -5.1608e-01,  6.0018e-01],\n",
            "        [ 4.1451e-01,  1.3664e+00,  1.3947e+00, -7.3959e-01, -4.8333e-01,\n",
            "         -7.4029e-01,  3.1428e-01,  1.4156e-01, -3.0158e-01, -1.4033e+00],\n",
            "        [-1.3271e+00, -9.9475e-01, -4.9400e-01,  1.1366e+00, -4.6184e-01,\n",
            "          1.4200e+00,  8.2107e-01, -6.7529e-02,  9.4907e-01, -3.9834e-01],\n",
            "        [ 6.8990e-01, -1.3129e+00,  3.7804e-02, -1.1702e+00,  2.3664e+00,\n",
            "         -6.3234e-01, -3.6152e-01, -1.6917e+00, -1.3839e+00,  4.8687e-01],\n",
            "        [-1.0020e+00,  3.2949e-02,  1.5164e+00, -4.3893e-01, -3.9991e-01,\n",
            "         -1.3291e+00,  1.5914e+00, -1.2081e-01, -4.8302e-01,  1.1330e-01],\n",
            "        [ 1.1226e+00,  1.2491e+00,  1.4194e+00,  1.5193e-01,  1.0966e+00,\n",
            "         -6.8369e-01,  6.6043e-02, -7.7380e-04, -1.2605e-01, -6.1262e-01],\n",
            "        [-4.8355e-01, -5.4189e-01, -1.0597e+00,  3.0573e-01,  4.1506e-01,\n",
            "         -7.1741e-01,  2.0587e-01,  2.7220e-01,  6.0855e-02, -1.1774e+00],\n",
            "        [ 1.6217e+00,  8.5127e-01, -4.0047e-01, -6.0883e-01,  7.1336e-01,\n",
            "          5.2985e-01, -9.1013e-01,  6.8631e-01, -4.5031e-01, -7.2966e-02],\n",
            "        [-5.4795e-01, -1.1426e+00, -1.0009e+00, -6.3100e-02, -9.6068e-01,\n",
            "          8.3139e-01,  1.1799e+00, -3.3143e-01,  6.4950e-01,  9.4959e-02],\n",
            "        [ 9.5283e-01,  1.1891e+00, -5.6830e-01, -8.5015e-01, -9.6385e-01,\n",
            "         -2.5668e+00,  7.0961e-01,  8.1984e-01,  9.1435e-01,  1.0095e+00],\n",
            "        [ 8.9462e-01, -2.8780e-01, -1.3638e+00,  1.9296e-01, -6.1033e-01,\n",
            "          1.6323e-01, -3.9118e-01,  1.6985e-01, -8.7040e-01,  3.0508e-02],\n",
            "        [ 5.2169e-01, -4.6387e-01,  1.8238e-01, -3.8666e-01, -1.8300e+00,\n",
            "          3.6471e-01,  7.8932e-01, -1.3341e+00,  1.3439e+00, -1.2922e+00],\n",
            "        [ 7.6624e-01,  6.4540e-01,  7.7788e-01, -5.7623e-02, -1.3171e+00,\n",
            "          1.5819e-01,  2.5403e-01, -1.7906e-01,  1.1993e+00, -4.2922e-01],\n",
            "        [ 5.4387e-01, -5.2142e-01, -7.5755e-01, -7.5627e-02, -1.7376e+00,\n",
            "         -1.2535e-01, -1.3658e+00,  1.1117e+00, -3.7637e-01,  9.8742e-01],\n",
            "        [ 6.4150e-01, -1.3313e+00,  2.0071e+00, -1.2531e+00,  1.1189e+00,\n",
            "          1.7733e+00,  9.2260e-01,  4.8716e-01,  1.4920e+00,  1.3264e-02],\n",
            "        [ 1.8595e+00,  2.6221e+00,  3.6905e-01,  3.8030e-01,  1.2571e+00,\n",
            "          1.2173e+00,  5.8395e-01,  3.3843e+00,  4.7390e-01,  6.5034e-01],\n",
            "        [ 1.1662e+00,  1.6936e-02,  2.3372e-01,  1.4083e+00, -2.0686e+00,\n",
            "          8.6857e-01, -8.0322e-01, -1.1209e+00,  1.9564e-01, -7.8152e-01],\n",
            "        [-6.1194e-01,  6.0262e-01, -8.3618e-01, -3.3326e-01, -4.8010e-01,\n",
            "         -1.2872e+00,  7.3888e-01,  3.3895e-02, -1.1860e+00,  1.2986e+00],\n",
            "        [ 8.9667e-01, -2.1818e+00,  6.1277e-02,  8.5261e-02,  7.4813e-01,\n",
            "         -1.6356e-01,  3.0481e-01,  5.1303e-01, -1.2514e+00, -8.3081e-01],\n",
            "        [ 4.9816e-01, -1.2000e+00,  1.2711e-01,  4.4037e-01,  4.7277e-01,\n",
            "          3.6402e-01, -2.8120e-01, -1.0375e+00, -1.8737e+00,  2.3259e+00],\n",
            "        [-9.2039e-01,  6.6611e-01,  8.9822e-01, -1.5388e-01, -5.6820e-01,\n",
            "         -8.6795e-02, -8.4834e-01,  1.6489e+00,  1.6006e+00, -7.8589e-02],\n",
            "        [ 9.7003e-01, -6.7577e-01,  2.0425e-01, -2.6476e-02, -4.1379e-01,\n",
            "          5.1841e-01, -7.0154e-01, -4.3234e-01,  6.6608e-02, -9.1199e-01],\n",
            "        [ 3.6821e-01,  7.0497e-01, -1.0838e+00, -3.8893e-01,  8.1261e-01,\n",
            "          1.4981e+00,  3.1258e-01, -5.2286e-02, -1.8611e-01, -7.8841e-01],\n",
            "        [-1.2787e+00, -3.8427e-02,  1.9138e+00,  3.3784e-01,  2.0705e-02,\n",
            "          7.4287e-01, -3.0620e-01,  5.9373e-01,  4.5572e-01,  2.5033e-01],\n",
            "        [-1.3611e+00,  1.8018e+00,  1.5287e+00, -9.3240e-01,  1.3527e+00,\n",
            "          1.6028e-01, -4.1456e-01, -6.9024e-01, -2.2996e-01, -2.1723e+00],\n",
            "        [ 1.6077e+00, -8.0643e-01,  7.3201e-02, -2.0952e+00, -9.5362e-01,\n",
            "         -9.2473e-02, -1.0167e+00, -7.6757e-03, -1.3237e+00, -3.6746e-01],\n",
            "        [ 1.0117e+00, -1.4080e+00,  2.1296e+00, -1.5181e+00,  1.3873e-01,\n",
            "         -1.1798e+00,  1.1162e+00,  2.9159e-01,  2.9770e-01,  7.5923e-01],\n",
            "        [-2.7936e+00, -7.1115e-01,  5.2352e-01, -1.7106e+00, -7.8717e-01,\n",
            "          2.4992e+00, -3.0195e-01,  2.2069e-01,  1.5133e-01,  7.3939e-01],\n",
            "        [ 2.7310e-01,  2.7312e+00, -4.5870e-01, -1.5441e-01, -2.1314e-01,\n",
            "         -8.8802e-01, -1.0874e-01, -4.1890e-01,  1.4384e+00, -7.0684e-01],\n",
            "        [ 1.6513e+00, -5.1567e-01, -7.5318e-01, -5.5455e-02,  3.2203e-01,\n",
            "          4.4606e-01,  1.5230e+00,  1.2805e+00,  7.2196e-01, -5.9426e-01],\n",
            "        [ 1.9674e-01, -4.0626e-01, -1.3642e+00,  8.2057e-03, -4.0586e-01,\n",
            "         -7.1109e-01, -5.9511e-01, -1.4568e-01, -3.8542e-01,  8.1006e-01],\n",
            "        [ 9.5949e-01,  1.0351e-01,  8.2903e-01,  2.0921e+00,  1.4306e+00,\n",
            "         -2.5830e-01, -7.9175e-01,  4.7021e-01,  9.0639e-02,  1.7423e+00],\n",
            "        [-1.2660e+00,  3.8916e-01,  1.1128e-01, -1.5339e+00, -8.7439e-01,\n",
            "          2.1726e+00,  2.2524e-01, -7.7245e-02,  9.8569e-01,  1.2783e+00],\n",
            "        [-3.4867e-01, -8.2238e-01, -1.4740e+00, -3.5021e-01,  4.5902e-01,\n",
            "          5.3093e-01, -1.3615e+00,  1.9562e+00, -7.1250e-01, -1.5326e-01],\n",
            "        [ 8.2447e-01,  1.4659e+00, -1.0087e-03, -8.4943e-01, -1.6594e+00,\n",
            "          3.0629e-01, -1.7602e-02, -1.9953e+00,  1.2103e+00, -1.3310e-01],\n",
            "        [ 8.2437e-01,  7.9835e-01,  1.8890e+00,  5.9346e-01,  4.1699e-02,\n",
            "         -3.3566e-01, -1.2594e+00, -2.1307e-01,  3.4436e-01, -3.1016e+00],\n",
            "        [-1.4587e+00, -1.4318e+00,  1.3071e-01,  1.7127e+00,  6.4644e-01,\n",
            "          1.3794e-01,  5.2335e-01, -8.2118e-01, -4.7087e-01,  6.0164e-01],\n",
            "        [ 3.5015e-02,  8.4218e-01, -2.1079e-01,  8.0115e-01,  1.6917e-02,\n",
            "          8.0277e-02,  7.4484e-01,  1.3455e+00,  1.2975e+00, -9.6455e-02],\n",
            "        [ 1.3945e+00, -1.3005e+00, -7.3467e-01,  4.4657e-02, -1.5211e+00,\n",
            "          3.4784e-01, -3.9783e-01,  7.5833e-01, -5.3466e-01, -1.4576e-01],\n",
            "        [ 9.2130e-01,  5.2824e-01, -8.2284e-03, -1.4493e+00,  5.8851e-01,\n",
            "          7.0912e-01, -2.6448e-01, -2.9836e+00, -4.1460e-01,  1.4559e+00],\n",
            "        [ 3.3165e-01, -1.0001e+00, -5.0971e-02,  1.4310e+00,  3.6733e-01,\n",
            "         -1.9229e-02, -1.0667e+00, -1.9893e+00,  2.9731e-01,  4.3446e-01],\n",
            "        [-1.4201e+00, -5.5593e-01,  1.6862e+00,  9.8853e-01,  1.3676e+00,\n",
            "         -3.1974e-01, -9.1309e-01,  1.9192e+00,  8.5048e-01, -8.4964e-01],\n",
            "        [-1.4020e+00,  1.7225e-01, -2.2057e-01,  7.1181e-01,  3.4159e-01,\n",
            "          1.5886e+00,  1.4324e+00,  2.2762e-01, -1.1287e+00,  1.1242e+00],\n",
            "        [-2.8155e-01,  5.2819e-02,  4.2498e-01,  4.8258e-01,  9.0772e-01,\n",
            "         -3.6692e-01, -1.8579e-02,  2.8529e-02,  8.2297e-01, -8.8603e-01],\n",
            "        [ 1.4801e+00,  8.3915e-01,  1.8386e-01, -7.9397e-01,  1.3019e+00,\n",
            "         -1.0228e+00, -1.4068e+00, -2.3610e+00, -2.9049e-01, -1.3346e-01],\n",
            "        [-1.3382e+00,  4.7418e-01, -2.2940e+00,  7.7438e-01, -5.4527e-01,\n",
            "         -2.1582e+00, -1.6608e+00, -6.6374e-01, -2.6699e-01,  2.5842e-01],\n",
            "        [ 7.7580e-01, -9.9987e-02, -5.6147e-01, -5.9491e-01,  1.2687e+00,\n",
            "          1.2904e+00,  6.9300e-01,  1.1980e+00,  1.3964e+00, -7.1499e-01],\n",
            "        [ 1.4109e+00, -1.3144e+00, -1.3162e+00, -1.2524e+00, -1.6489e+00,\n",
            "         -2.7997e-01, -1.2407e+00,  7.4105e-01,  7.3784e-01, -8.5053e-01],\n",
            "        [ 3.6101e-02,  1.3407e+00,  9.8604e-01,  1.1324e-01,  1.9083e+00,\n",
            "         -1.4606e+00, -7.1111e-01, -3.8667e-01,  9.5783e-01, -8.2253e-01],\n",
            "        [-3.2305e-01, -1.2124e+00, -6.0039e-01, -1.4655e-02, -5.2238e-01,\n",
            "         -7.4018e-01,  1.6236e-01, -2.3700e-01, -9.6004e-01, -2.6212e-01],\n",
            "        [-4.2326e-01, -1.9508e+00,  1.8619e+00, -1.0779e+00,  8.8486e-01,\n",
            "         -8.3421e-01,  5.7890e-01, -6.5374e-01,  2.4182e-01,  1.3824e+00],\n",
            "        [ 1.1285e+00, -1.2123e+00,  2.6024e+00, -9.5724e-02,  1.8537e+00,\n",
            "          1.7170e-01, -5.8971e-01, -1.4395e-01,  5.1823e-02, -3.2848e-01],\n",
            "        [-2.2472e+00, -4.4790e-01,  2.3078e+00,  9.0559e-01,  7.0041e-01,\n",
            "          1.7930e+00,  8.7030e-01, -1.0553e+00, -1.3284e+00,  7.0607e-01],\n",
            "        [ 4.0820e-01, -2.3505e-01,  2.6021e-01, -2.4554e-01,  2.4651e-01,\n",
            "          1.3287e-01,  1.2191e-01,  4.7809e-01,  2.6442e-01, -8.8520e-01],\n",
            "        [ 7.8384e-01,  8.7324e-01, -1.9897e-01, -1.3616e+00, -5.1936e-01,\n",
            "          7.6482e-02, -3.5871e-01,  7.8779e-01, -1.2438e+00, -1.0805e+00],\n",
            "        [-4.4770e-01, -7.2882e-01, -1.6066e-01, -3.2064e-01,  4.1993e-01,\n",
            "         -3.5373e-01, -1.8270e+00,  6.5922e-01, -2.6274e-01,  9.3150e-01],\n",
            "        [-4.5935e-01, -9.4195e-01, -8.4712e-01, -4.0895e-01,  5.6657e-02,\n",
            "          9.5321e-01,  8.5207e-01, -1.6947e+00,  1.1806e+00, -2.8929e+00],\n",
            "        [-1.1376e+00,  7.4885e-01, -2.2847e+00, -4.5605e-01,  5.1367e-02,\n",
            "          6.9502e-01,  1.8352e+00, -1.9180e+00, -1.4741e+00, -9.6152e-01],\n",
            "        [-1.0874e+00,  1.5792e+00, -1.3386e-01, -5.8557e-02,  1.2574e-01,\n",
            "         -5.5258e-01,  5.2996e-01, -2.9358e-01,  2.0778e-01,  2.9771e-01],\n",
            "        [-1.0284e+00,  4.0444e-01,  2.1426e+00, -5.1537e-01,  2.4006e-01,\n",
            "         -7.9066e-01, -8.1320e-01,  1.4148e-01,  4.9279e-01, -5.1283e-01],\n",
            "        [ 3.0062e-01,  7.7347e-02,  6.9914e-01, -3.6270e-02, -3.7976e-01,\n",
            "         -8.5345e-01,  6.6743e-01, -8.0360e-01, -1.3776e+00, -4.4105e-01],\n",
            "        [-2.3463e-01,  2.7824e-01, -1.2937e-04, -1.2450e-01, -1.2248e+00,\n",
            "          9.6289e-01, -1.5785e+00,  6.7160e-01, -1.2137e-01,  8.1387e-01],\n",
            "        [-3.8159e-01,  6.2465e-01,  1.2306e+00,  4.2521e-01, -1.6383e-02,\n",
            "         -1.0749e-01, -4.9028e-01, -7.3327e-02, -1.0329e+00, -4.3199e-01],\n",
            "        [-3.4501e-01, -1.1962e-01,  1.1862e+00, -1.2203e+00,  1.5731e+00,\n",
            "          7.2509e-01, -5.8867e-01, -9.9579e-01, -2.9336e-01,  2.1066e+00],\n",
            "        [-1.0875e-01,  6.0834e-01,  5.2450e-01,  2.0828e-01,  2.8003e+00,\n",
            "          1.1653e+00,  6.8309e-01,  1.0637e-01,  3.5032e-01,  1.2110e-01],\n",
            "        [ 3.9462e-01, -7.5862e-01, -1.3669e+00, -1.6847e-01,  8.1554e-01,\n",
            "         -8.2406e-01,  8.9328e-01, -3.8688e-01, -1.0566e+00, -2.0851e+00],\n",
            "        [ 1.8209e+00, -1.2469e+00,  9.6943e-02, -7.9121e-01,  3.7120e-01,\n",
            "          1.5118e+00,  1.6813e+00,  1.1009e-01,  7.8541e-01,  1.3402e+00],\n",
            "        [ 1.1900e+00,  1.4109e+00,  7.9801e-01,  4.9413e-01,  1.1134e+00,\n",
            "         -8.0178e-01,  2.2057e+00, -1.7395e+00,  2.3484e-01,  8.8615e-02],\n",
            "        [-3.4769e-01,  8.4907e-01,  5.3031e-01, -1.6844e+00, -1.1636e+00,\n",
            "         -3.3510e-01,  7.0421e-01, -5.6285e-02, -1.4897e+00, -1.5195e+00],\n",
            "        [-5.2661e-01, -4.8971e-01, -1.5185e-01,  3.1875e+00, -2.9337e-01,\n",
            "          1.3978e+00, -9.1666e-01, -7.7937e-01,  2.7535e-01, -1.7002e+00],\n",
            "        [ 5.6745e-01,  5.8132e-01,  7.7053e-01, -1.1304e+00,  9.9646e-01,\n",
            "         -1.1810e+00,  7.3784e-01,  2.0243e+00, -2.9773e-01,  1.5023e+00],\n",
            "        [ 1.9485e-03, -2.0979e-01,  1.2010e+00,  6.7560e-01, -4.6115e-01,\n",
            "          2.4943e-01, -1.7671e+00, -1.4565e-02, -7.4869e-01, -3.8440e-01],\n",
            "        [ 1.4350e-01, -8.1268e-02, -9.0254e-01, -2.3575e-01, -2.3813e+00,\n",
            "          7.3334e-01, -1.1129e+00, -4.3420e-01, -1.5212e-02,  5.4272e-01],\n",
            "        [-5.0588e-01,  1.0542e-01, -2.1039e+00,  4.0705e-01, -1.0487e-01,\n",
            "          2.4768e+00,  5.7691e-01,  1.4731e-01,  1.6910e+00,  7.4263e-01],\n",
            "        [ 3.0812e-01,  2.0517e+00, -1.4078e+00, -8.0111e-02,  5.1941e-01,\n",
            "          1.1709e+00, -1.9454e-01, -1.1237e+00,  2.5675e-01, -5.7640e-01],\n",
            "        [-3.4975e-01, -1.3381e+00, -4.3891e-01, -5.8502e-01, -4.2500e-01,\n",
            "         -2.2851e+00,  5.9081e-01,  3.1265e-01,  1.0613e-01, -3.0671e-01],\n",
            "        [ 8.6423e-01, -1.0659e+00,  2.3014e-01, -5.7808e-01, -2.5223e-02,\n",
            "         -1.2018e+00, -5.6145e-01, -9.4646e-01, -7.4197e-01,  1.5562e-01],\n",
            "        [-1.0998e+00,  6.1936e-01, -1.8343e-01,  3.6662e-01,  1.0132e+00,\n",
            "          6.3464e-01,  8.7688e-01,  8.1428e-01, -5.8523e-01, -1.2098e+00],\n",
            "        [ 3.1384e-01, -2.6485e-01, -7.8818e-01,  5.6844e-01,  7.6224e-01,\n",
            "          5.5685e-01, -2.8297e-01,  5.3583e-01, -2.9162e-01, -9.5914e-01],\n",
            "        [ 5.5851e-01,  3.4915e-01,  8.4837e-01,  2.0355e+00,  6.5747e-01,\n",
            "          6.6454e-01, -1.0752e+00,  1.7599e-01, -5.0640e-01, -8.4417e-01],\n",
            "        [-2.2144e-01,  2.2746e+00,  1.7086e+00, -1.5738e+00, -4.5267e-01,\n",
            "          1.1752e+00, -9.6035e-02,  1.0644e+00,  1.4888e+00,  8.8256e-01],\n",
            "        [ 7.2549e-01, -1.6016e+00, -6.1539e-01,  2.2441e+00, -2.0364e+00,\n",
            "          5.2469e-01, -6.9703e-01, -8.7932e-02, -1.0814e+00, -4.2052e-01],\n",
            "        [-1.5535e+00,  1.0887e+00,  1.1260e-01, -1.4679e+00, -1.7168e+00,\n",
            "         -5.5025e-01,  9.2329e-01, -4.8524e-01, -5.5359e-01, -7.5812e-01],\n",
            "        [ 1.4171e+00,  1.6868e-01, -1.1421e+00,  6.0696e-01, -1.6116e+00,\n",
            "         -1.2148e+00, -1.6696e-01,  1.0514e+00, -6.1845e-01,  5.4566e-01],\n",
            "        [-7.6913e-01,  7.9336e-02,  1.0386e+00,  3.7699e-01,  2.2219e-01,\n",
            "         -2.7424e-01,  5.0576e-01, -1.1371e+00, -7.5818e-01,  4.2283e-02],\n",
            "        [-1.2759e+00,  2.2149e+00, -5.9917e-01, -3.2912e-01, -1.7733e+00,\n",
            "         -9.9073e-01,  6.3486e-01,  1.0238e+00,  5.4232e-01,  9.7972e-02],\n",
            "        [-1.4411e-01, -5.2993e-01,  2.4401e+00, -1.9129e+00,  3.1077e-01,\n",
            "         -1.4763e+00,  1.5560e+00,  8.9240e-01,  7.0562e-01,  1.4172e+00],\n",
            "        [-2.9485e-01, -2.7986e-01,  1.0837e+00,  1.7298e-01, -7.6097e-01,\n",
            "         -1.2726e+00, -6.2674e-01,  1.3713e+00, -4.3869e-01, -1.3193e+00],\n",
            "        [ 1.7944e+00, -2.1130e-01, -2.3167e-02, -1.1093e-02, -9.9528e-01,\n",
            "         -2.9935e-01, -5.7769e-01,  1.1428e+00, -5.9470e-01,  5.3631e-01]]) tensor([[1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1],\n",
            "        [0],\n",
            "        [1],\n",
            "        [1],\n",
            "        [1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Creamos tensores para los pesos inicializados con valores aleatorios muestreados de una normal ($\\mu = 0$ y $\\sigma = 1$) y el sesgo inicializado con cero."
      ],
      "metadata": {
        "id": "O_Gcq2hhW8Lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = nn.parameter.Parameter(th.randn((d, 1)))\n",
        "b = nn.parameter.Parameter(th.zeros((1, 1)))\n",
        "\n",
        "print(w, b)"
      ],
      "metadata": {
        "id": "KXmyOCkTW-UB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d39f06b-9435-4da3-82bd-7a8fa6f3bff2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-1.5897],\n",
            "        [-0.0405],\n",
            "        [ 1.9010],\n",
            "        [-0.6620],\n",
            "        [ 0.2589],\n",
            "        [-1.0627],\n",
            "        [-1.4913],\n",
            "        [ 0.1673],\n",
            "        [ 0.7528],\n",
            "        [ 0.6113]], requires_grad=True) Parameter containing:\n",
            "tensor([[0.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos obtener los gradientes de $\\mathbf{w}$ y $b$ respecto a la [entropía cruzada binaria](https://en.wikipedia.org/wiki/Cross_entropy) usando diferenciación automática.\n",
        "\n",
        "![](https://pytorch.org/tutorials/_images/comp-graph.png)\n",
        "\n",
        "Fuente: Tutorial [Automatic Differentiation with `torch.autograd`](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html).\n",
        "\n",
        "Nota que en esta gráfica de cómputo no se observa la función sigmoide. Esto se debe a que en PyTorch hay una versión de la entropía cruzada binaria que recibe los _logits_ como entrada.\n",
        "\n"
      ],
      "metadata": {
        "id": "62Z-cB8DVv8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat = neurona_sigmoide(w, b, X)\n",
        "fp = ecb(y, y_hat)\n",
        "fp.backward()\n",
        "\n",
        "print(w.grad, b.grad)"
      ],
      "metadata": {
        "id": "ZQpo-mcFXPuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7d5078-8b05-4ebe-cd66-13cb1b32a533"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-15.5506],\n",
            "        [ 10.1311],\n",
            "        [ 16.7294],\n",
            "        [ -5.6696],\n",
            "        [  1.5938],\n",
            "        [-14.8970],\n",
            "        [-13.9856],\n",
            "        [  4.4366],\n",
            "        [  9.3861],\n",
            "        [ 12.7488]]) tensor([[-7.1167]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio\n",
        "Genera un conjunto de datos sintético, programa la propagación hacia adelante y calcula los gradientes de la función de pérdida de la suma del error cuadrático medio respecto a los pesos y sesgos para $K$ regresiones lineales."
      ],
      "metadata": {
        "id": "WHkUtKnsx0qZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando un modelo de regresión con descenso por gradiente\n",
        "Vamos a entrenar un modelo de regresión lineal con [descenso por gradiente](https://youtu.be/IHZwWFHWa-w) usando la diferenciación automática de Tensorflow.\n",
        "\n",
        "Primero generamos un conjunto de datos sintético y lo almacenamos en una instancia de `Tensor`."
      ],
      "metadata": {
        "id": "lYJTQtdb5lD5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cd212ccQ9taq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos las instancias de `Parameter` para $\\mathbf{w}$ y $b$ las cuales inicializamos con valores aleatorios (normal con media 0 y desviación estándar 0.1) y con ceros, respectivamente."
      ],
      "metadata": {
        "id": "3kc0MjqmplU8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYnpFtmUT7ZS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos una función para producir un tensor de salidas a partir de un tensor de entradas, esto es,\n",
        "$$\n",
        "\\hat{y} = b + \\mathbf{w}^\\top\\mathbf{x}.\n",
        "$$\n"
      ],
      "metadata": {
        "id": "VQh_QEMrqWrT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMQQfEePqXZ1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora definimos nuestro ciclo de entrenamiento en el cual generamos la salida para cada entrada, calculamos los gradientes de $\\mathbf{w}$ y $b$ respecto al error cuadrático medio usando la diferenciación automática de Tensorflow y finalmente actualizamos $\\mathbf{w}$ y $b$ con la regla de actualización del descenso por gradiente:\n",
        "\n",
        "$$\n",
        "\\boldsymbol{\\theta}^{[t + 1]}   = \\boldsymbol{\\theta}^{[t]} - \\alpha \\nabla \\mathcal{L}(\\boldsymbol{\\theta}^{[t]})\n",
        "$$\n",
        "donde\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\boldsymbol{\\theta} & = \\{\\mathbf{w}, \\mathbf{b}\\}\\\\\n",
        "\\nabla \\mathcal{L}(\\boldsymbol{\\theta}^{[t]}) & = \\left[  \\frac{\\partial \\mathcal{L}}{\\partial  \\theta_0^{[t]}}, \\cdots , \\frac{\\partial \\mathcal{L}}{\\partial \\theta_d^{[t]}}\\right]\n",
        "\\end{align*}\n",
        "$$    \n",
        "\n",
        "A $\\alpha$ se le conoce como tasa de aprendizaje.\n"
      ],
      "metadata": {
        "id": "EEHP6ZlSp58d"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIW3x4vMpxr0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos el modelo."
      ],
      "metadata": {
        "id": "7IaB_ffwstBo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cg6Dt5vw_VM5"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos el valor de la pérdida por época."
      ],
      "metadata": {
        "id": "qWq-lMYzszHA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFn9I3rXAdtK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el entrenamiento de redes neuronales profundas es común usar aproximaciones estocásticas del descenso por gradiente (o variaciones). Estas aproximaciones estiman $\\nabla \\mathcal{L}(\\boldsymbol{\\theta}^{[t]})$ y actualizan los parámetros (pesos y sesgos) usando un minilote $\\mathcal{B}$ de ejemplos (en lugar de todo el conjunto) de entrenamiento, donde $\\vert \\mathcal{B} \\vert$ es un hiperparámetro. Una estrategia para generar los lotes es dividir y ordenar aleatoriamente el conjunto de $n$ ejemplos de entrenamiento en $k$ minilotes ($\\vert \\mathcal{B} \\vert \\times k \\approx n$) e ir tomando lotes consecutivos hasta pasar por todo el conjunto. Aquí una época ocurre cada vez que se han considerado los $k$ minilotes."
      ],
      "metadata": {
        "id": "U6roxslovyls"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EWlKUlTI_Lol"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizamos el modelo."
      ],
      "metadata": {
        "id": "LBxR5WsKBTFS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tcd81LquA-zl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficamos el valor de la pérdida por época."
      ],
      "metadata": {
        "id": "SIxdI9udBVg7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "geNTYCeZAdT8"
      },
      "execution_count": 32,
      "outputs": []
    }
  ]
}